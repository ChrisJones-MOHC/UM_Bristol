var store = [{
        "title": "Backups",
        "excerpt":"  Home and ummodel are backed up.   Not sure if every night or every 7 days?   ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_technical_notes/Backups/",
        "teaser": null
      },{
        "title": "Clustersubmit",
        "excerpt":"  Clustersubmit edits the submit scripts on the fly for a specific machine.   Streamlined as possible.   Still has weird pdksh.   Some user-specific bits.   Paul has documented this - see webpages.  Need to shift this onto github/markdown.   ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_technical_notes/Clustersubmit/",
        "teaser": null
      },{
        "title": "Documentation",
        "excerpt":"Back to HadCM3_technical_notes   Use markdown for documentation (.md files) and link to github.   Could set up a Jupyter Hub for python on one of BRIDGE machines.  Discussed this with Fabien.   Could set up a BRIDGE account on github (Greg may have one that he controls already).   Could set up an organisation on github.   Quick start for writing docs on github: https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/quickstart-for-writing-on-github   Quick start for github pages: https://docs.github.com/en/pages/quickstart   Obsidian:  https://forum.obsidian.md/t/internal-links-not-working-on-github/50058/2 To use Markdown links from the start so you don’t have to convert them later, disable Settings &gt; Files &amp; Links &gt; Use Wikilinks.   To upload a file from PC to github: On web interface, + -&gt; New repository.  Choose existing folder.   Downloaded GitHub Desktop which seems quite nice.   Had to play around a bit with the .obsidian folder.  I had to add .obsidian to the .gitignore file.  And then remove from github.  But keep on local folder (had to remove and then remake “vault”)   Now seems to sync quite well.   Git Training: https://chryswoods.com/introducing_git/   GitHub Training: https://chryswoods.com/git_collaboration/   Dan will merge documentation and start new markdown version.  Test with Niels in first instance.   ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_technical_notes/Documentation/",
        "teaser": null
      },{
        "title": "Downloading",
        "excerpt":"  Crontab.   Needs root access   All users have heir own crontab.   ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_technical_notes/Downloading/",
        "teaser": null
      },{
        "title": "Ensembles",
        "excerpt":"  Ensemble script writes wrapper around jobs.   Doesn’t work with more than one node.   Ensemble script run on sub nodes.  ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_technical_notes/Ensembles/",
        "teaser": null
      },{
        "title": "Local hardware",
        "excerpt":"  BluePebble is possibly the future of local hardware.  Could have a head-node plus a disk.  However, Digital Labs may be replacing Bluepebble.  See University_HPC   Need an eocene replacement.   Also need to replace oligocene/holocene.   Fund via Capital Bids?   Oligocene: web server.  Very old.   Holocene4: sitting around doing nothing   Triassic: very old   Silurian: also old   David Gardner is currently overloaded and so has little time for new development work.   Rocky8 now on miocene.  But not tested.  gfortran does not compile all the scripts.  Intel compiler is fine though.  qplot does not compile.   Plan - open miocene up to group.  When working, send to group and ask for feedback.   Eocene2 doesn’t work with old servers.   Needs a 2-week blast on this.   ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_technical_notes/Local_hardware/",
        "teaser": null
      },{
        "title": "Model_install",
        "excerpt":"  The original CD with the code from the Met Office is lost   gcom is the hardest part of the install.  Gethin does this part.   nupdate is also a challenge.   Gethin has a cut-down version of the install.   Once the cut-down version is running, Paul modifies to make changes associated with running on different machines etc. invisible to the user, via clustersubmit.   Could put the model on github (Richard at BRICS also suggested this).   ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_technical_notes/Model_install/",
        "teaser": null
      },{
        "title": "PUMA",
        "excerpt":"  Two versions: 4.5.3 versus 4.5.1   Andy Heaps, who used to maintain PUMA, has now retired.   The umui runs with tcl, and only an older version of tcl.   ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_technical_notes/PUMA/",
        "teaser": null
      },{
        "title": "Standard jobs",
        "excerpt":"  Standard jobs are under user swsvalde on the umui.  This took quite a lot of time to set up.   The standard STASH outputs are also held under swsvalde.   pi files - STASH is now the same.   Every 12-24 months these are updated - episodic intensive work.  ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_technical_notes/Standard_jobs/",
        "teaser": null
      },{
        "title": "University HPC",
        "excerpt":"  Paul Valdes - Craig Butts (HoS, chemistry) got money (from EPSRC?) for BC/BP replacement.  Cloud but local.  Dynamically partitioned.  But disk space is an issue.   David Manley - £1.2 million for x86 replacement.  EPSRC money.  Key people are Annela Seddon (APVC), Stacey Downton (leading on IT side).  Speak to Stacey about BC4 replacement.  BRICS - Bristol Research….  Also Simon Hanna who is the Academic Lead.   Simon Hanna  “Digital Labs”.  Virtual Machine. One Partition will be “BC5” Has a teaching component. Sadaf’s priority. Questions for Simon:     Size and speed?   Scalability - can we add to it?  S: Would like to.   Storage?   Where? S: physics tank room   Charging model: Baseline FPU   Longevity?   Timescale?   Role of ACRC? BC4 is currently £1M per year to run.  May be a 6-month option to extend.  18th Dec: meet with Bond, Wooly, and others. Annela Seddon is new APVC Faculty FRD.  Simon had a meeting with her, but also attended by Ian Bond.  “No, sorry, I can give no update.  I’ve tried to find out what is going on, but I have also been told to wait.  We are not waiting for each other, we are specifically awaiting permission from above to spend the money.  I think there are many factors in play here but anything I might say at this point would be guesswork, so best not said.  I suggest agitating with Heads of School and above - we wanted to move with the project at the start of January in order to have a viable service before BC4 gets shut down.  The longer we wait, the less likely that becomes.”   Paul Valdes and Gethin Williams and Sadaf and Simon - Options for HPC     BC4 : maybe extended 6 months?  Few £100.  Guy Poppy VC for research.  Ian Bond currently decision maker while Guy spins up.  Climate is one of our uni Strategic Objectives.   Bluepebble.  our jobs may have low priority as it favours single-core jobs.  We have 4 dedicated nodes.  Never used for a large ensemble (2 week queueing time).  Could buy more nodes.  BUT, still planned to be turned off.  May work multi-node for high-res model.  Will likely out-live BC4.   Maybe late 2026 turn-off.  But storage may deplete faster.  Currently working really well as the “new silurian”.   Digital Labs. We don’t have an account on this.  Maybe due to EPSRC funding.  Stacey Downton controls (Gethin says maybe not?).  Low diskspace?  Would multi-node jobs work?  Sadaf is the lead.  Uses OpenStack.  Flexible but complex.  StackHPC is the company.  “mother of all learning curves”. Uses VMs and cubinettis.  Ultimately, the user sees a slurm cluster. Craig Butts EPSRC £300k.  But no staff time for this.  Chris Woods is now employed on Isambard (in Thailand).  Sadaff in favour of this.  £1.3 million on x86 chips.  40 nodes x 200 cores.  Sadaff will ask someone to slurmify this.  The Gethin install the model.  Summer of this year for slurm to be there?  No idea how fast it will be.  Very filesystem and node dependent.  Sadaf is now also head of Isambard.  Simon says “The plan is to get a prototype x86 service running as soon as possible i.e. this month, and get some early users testing it.  Then we need to start the procurement exercise for the new nodes in order to have a replacement service running by the summer in time for the BC4 shutdown.  We had the promise of a substantial investment to kickstart the venture.  But, it’s a complex project and lots of people involved and we are waiting for a project manager to be appointed, so I’ve nothing definite to report on timescales.  It’s unlikely the prototype service will start now until February. However, there was acceptance that the service to users should not be interrupted over the summer, so everyone is working to that goal.”….”Yes, I have you and others in Geography in mind as test users.  Also, some astrophysicists and chemists.  It’s important to stress test the system before we commit, and Sadaf is keen that we do this.” Key thing is to press for the necessary storage on this system.  Think this sits under Bristol Centre for Supercomputing (BriCS).   Archer2 Michael Mimmiter - Simon Tett.  Ensemble script on pre-Archer.  FAMOUS in container on Archer.  Maybe good for high-res model.  FPU if have a grant- NERC grant may help.  We may have low queue priority.  Gethin thinks may be OK.  Gethin could port to Archer - will need buy-in from Grenville and Annette.   Isambard 3 / AI Gethin.  nupdate is an issue.  Original CRAY.  Mike Blackburn wrote a C nupdate.  CRAY did release source code.  Isambard 2 - 2 years per day!  Maybe 10 years per day (Gethin updated this to say it is 2-10 times slower than on BC4.  But largely irrelevant as Isambard 3 is very different to Isambard 2).  Ideal solution if it can work.  Bristol has an FPU component that is very big. May be a panel for FPU component. Nodes are “Grace-Grace” = two Grace chips on a node.  Isambard 3 - UoB has 10% of this.  Gethin working on installing here.  nupdate (written in fortran?) is an issue.  The original code is a “binary blob” that is unpacked by nupdate.  Maybe ready sooner rather than later?  Arm design, build by nvidia, called Grace.  Not x86!  One issue is the “swapbounds” step in the UM, which brings all calculations back to a single node every timestep, and does not scale well on non-x86 chips. Simon says “Regarding the code issues, I spoke with Sadaf Alam and Simon MS, and they are keen that the slow running should be resolved.  They have a sort of hotline to HPE for support with this sort of problem and have asked that Gethin raise tickets with them for investigation.  I’ve passed this on to Gethin so you might get some progress there.  The call for general UOB access to Isambard 3 (and Isambard AI) will go out this week for short projects beginning in February.”….”Regarding Isambard, I think everyone is keen for it to be a success, including the vendors, so we should take advantage of this support while it is available.”   Condor PCs in department.  Speak to Jeff.  Not a good solution according to Gethin.   Cloud Computing Price may increase and costly.  Data output?  May be very expensive for volatile data.  ~£20k per year for 500 TBytes volatile.  If in a container then may work.  Code is working with gfortran.  Informally, Stacey recommends considering this approach.   Fanny’s machines Won’t be replaced.  Not a long-term solution.   Self-service cluster (aka NextGen).  Keith Woolley.  Tony Payne used.  Not many cores.  Not for HPC.  But could be a test for the cloud.  Uses VMWARE version of openStack.  Has a lot of security.  Stacey has EPSRC grant to inject funding.  ACRC sites in IT services.   Organisation Keith Woolley &gt; Matt Shard &gt; Steph Downton Woolley &gt; Steve Edge… &gt; Simon Spate &gt; Duncan Baldwin &gt; David Gardner Keith Woolley and Sadaf lead IT services and BriCS respectively. Previously was Sadaf and Chapman.  Gethin currently doing extra role as Chapman left. ACRC will likely be split between BRiCS and IT services. Digital Labs will sit in BriCS (with Isamabrds). NextGen-AI will sit in IT services. RDSF will sit in IT services.   Gethin UK-wide - many groups struggling with UM install due to move from Centos7 to Rocky8. 1-day MOAP, 1-day Paul.  3 days ACRC.   Isambard 3 application           How many CPU hours are you requesting? They ask how many CPU-hours that we will need for the project.  Looking at the spec, I am assuming that we will use one (half) node, so 72 cores, and probably the testing over 3 months will amount to a few hundred years of simulation (let’s say 1000 years) (if things go well and we get to the point of evaluating the model).  This might be 20 days of solid integration (unless the model is very slow).  So, 72 * 20 * 24 = 34,560, so ask for 50,000 CPU-hours?            How many terabytes (TB) of disk space in total do you expect to need? For disk-space, I guess 200 GB will be enough, just for testing?            What is your proposed project name?  HadCM3-Isambard3            Please give a brief description of your project (about 250-500 words). We have been running a climate model on BC4 for about 15 years or so.  We have had great success with this, and it has been the primary tool of our research group which averages about 20 people or more in terms of funded postdocs and PhD students.  Given the impending end of BC4, it is imperative that we make the transition to either Digital Labs, or NextGen/self-service-cloud, or to Isambard 3/AI, as soon as possible, to ensure continuity of service and research across multiple UKRI/EU/industry funded projects.  However, this is non-trivial.  The (fortran) code is exceptionally complex and large, and is surrounded by wrappers, in total of order 1 million lines of code.  As such, we need considerable time to port the code.  In this project, we would like to continue our work, carried out by Gethin Williams, to port the code to Isambard.  This involves compiling, running, evaluating, and setting up the modelling infrastructure.  We anticipate using just one node (actually half a node, so 72 cores if I have understood correctly from the Isambard 3 spec).  Plus the head-node for compiling and testing wrapper scripts etc.  I am guessing 20 days of continuous run time in total over the 3 month period, but this is a best(largest)-case scenario, and assumes that we get onto the evaluation phase of the project (benchmarking results to previous simulations), which is very much a “stretch goal”.       Stacey Downton     “self-service-cloud” (preferred name) and NextGen are one and the same.   It is currently unclear which of self-service-cloud and DigitalLabs will go ahead, but Ian Bond has “promised” ~£1M for one or the other. It is hoped that the spec will be determined in Jan/Feb.   The timescales of when this will be available for users (i.e. with slurm, and looking to the user like something similar to BC4) is unclear, but the university is hoping for continuity of service (i.e. it will be ready when BC4 closes). On Wednesday 18th December a sub group of the Digital Research Infrastructure Board (Bond, Sadaf, Stacey, Woolley, O’Shea, Guy Poppy Polly Eccelstone, others) met to consider the Ongoing HPC provision options for the University of Bristol during and beyond the Isambard commissioning. The group discussed the urgency of making a decision on this issue, given the age and running costs of the large scale BlueCrystal 4 HPC service, and considered the options for replacing the University’s centralised cpu provision as set out in Simon Hanna’s HPC continuity options paper.  It was agreed in principle that approximately £1 million of the £1.13 million ACRC 24/25 capital budget should be invested in the replacement HPC cpu and compute storage capacity. A project will be set up in January 2025 to plan for the procurement of the replacement system, the decommissioning of BlueCrystal 4 and the migration of the BC4 users. The precise specifications and costings for the replacement capacity will be determined in Jan/Feb 2025   See Simon Hanna document.   Sadaf Met with Sadaf Alam and Gethin Williams and Richard Gilham. Sadaf said that NVIDIA will not really be interested in our code as it is too old and bespoke, so no support for installing on Isambard.          Now to mid-term: continue with x86 UoB HPC continuity on Digital Labs cluster.  It currently has 10x2 AMD x86 processors with 128 cores per node (Gethin can confirm).  Dan will check timeline with Ian Bond.  We are ready to go waiting for the approval where we can gradually increase x86 capacity to close to 80% of BC4 CPU core count in the next 6 months.  *It is great to hear that Digital Labs will eventually be close to 80% of BC4 core count.  This is really good news for us.  I will push Ian on the timeline for the £1M investment. Is the 80% what we expect to get from Ian Bond’s £1M?  Or does 80% include an expectation that users will also provide funds for cores?  Are the initial 10 AMD processors ready to use for testing now?  i.e. is slurm installed and can we have a test account, please.   As I explained, for continuity of service we really need to start the work of installing and benchmarking our code asap. A key thing for us is plenty of disk space on the cluster, as we produce a lot of data!  How much disk space is currently on Digital Labs, what is the aspiration for eventual disk space, and how does this compare with what is on BC4?            Medium to long term (6+ months plus) explore opportunities for code modernisation on newer multi-core x86 and ARM processors.  This would require a couple of RSE resources and possibly community efforts. Yes, Gethin has started on this.  How much he works on this, and how much on installing the model on Digital Labs, is a decision that depends on the answers to the above questions, I guess.            In parallel, find out details and plans for the next gen facility by IT services (I do not have visibility). I have chatted to Sophie Downton about this.  She seemed unclear as to whether Ian’s investment of £1M would go to Digital Labs or to NextGen, so this makes things a little confusing for us.  It would be good to have some clarity - I will chat to Ian about this too.  From what I heard from you, it sounds like Digital Labs would be our preferred option.       Ian Bond Thank you for your time on Tuesday - it was much appreciated.   In terms of the HPC part of our discussion, see below for my understanding of what we discussed - please let me know if any of this is incorrect.  If you are happy then I will disseminate this more widely in Geography.           As part of the “x86 HPC” community, I am really pleased that the Faculty recognises the importance of maintaining an x86 capability, and grateful for the investment of ~£1 million.            The Faculty recognises the importance of “continuity of service”, in particular for ongoing funded grants and deliverables, and that this will mean a period of overlap between the old and new systems due to the timescales required to port complex codes, including extending BC4 if necessary (which will hopefully not be needed!)            The new system will be DigitalLabs and will be procured, maintained, and supported through BriCS, led by Sadaf Alam.            I will email Sadaf to ensure that the Users have meaningful input into the specification of the new machine, in particular with regard to ensuring an appropriate balance between storage and compute.      ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_technical_notes/University_HPC/",
        "teaser": null
      },{
        "title": "Accessing Scotese",
        "excerpt":"    Introduction   This document describes how to access BRIDGE climate outputs.  In particular, it focuses on ensembles of HadCM3L Phanerozoic simulations.   If you do download these simulations, then please let us know, and we always like to be involved in the science that you carry out with the simulations!  In particular, some of the simulations are unpublished, and if you use these then we would ask to be included as co-authors in any papers that use them.   We have a number of HadCM3L Phanerozoic ensembles; each one can be identified by its 5-letter PUMA (Providing Unified Model Access) code.  Each ensemble consists of 109 simulations through the Phanerozoic.   The “standard” ensembles that we currently have are:   “texy” series: These are the “Smooth CO2” simulations described in Valdes et al (2021).   “texp” series: These are the “Foster CO2” simulations described in Valdes et al (2021).   “tfke” series: These are similar to the Valdes et al (2021) simulations, but have several improvements to the underlying climate model (e.g. tuned atmospheric and ocean physics to give more polar amplification, in line with paleo temperature proxies), better ocean solver, reduction of gridpoint noise).  Also a change to the late Cretaceous and early Cenozoic CO2, to be more in line with Rae et al. (2021).  These simulations are currently unpublished, but we are in the process of writing them up.  They were included in Judd et al (2024), but only a very limited number of variables.   “tfks” series: As tfke, but with a CO2 evolution through the Phanerozoic that is tuned to give GMSTs in line with Scotese et al (2021).  These simulations are currently unpublished, but we are in the process of writing them up.   “xqbp” series: As tfks but with more output variables.  Run for 110 years.   13/1/2023: The current “best” ensemble is tfke if you have most confidence in the CO2 proxies + model climate sensitivity, and tfks if you have most confidence in the temperature proxies from Scotese et al. (2021).   The naming convention of the 109 simulations is as follows, e.g. for tfke the simulation names are:   tfke{a..z}  tfkE{a..z}  tfKe{a..z}  tfKE{a..z}  tFke{a..e}   where tfkea is 0Ma and tFkee is 540 Ma.   However, note that the last 5 simulations of the texp series are texq{a..e} rather than tExp{a..e}, and that some of the simulation names in texp are appended with a “1” or a “2” – for a list see here: https://www.paleo.bristol.ac.uk/ummodel/scripts/html_bridge/scotese_02.html   There are also some other ensembles available, but they are not all published, and some may not be fully spun up, so please do get in contact before using them.  See Appendix 1.   Standard text for describing tfks, tfke simulations   tfke and tfks  The simulations are similar to those described in detail in Valdes et al (2021).  Compared to the simulations presented in Valdes et al (2021), the simulations used in this paper have undergone a number of developments, associated with improvements to the model itself, and to the experimental design. The most significant of these are summarised here.  The version of the climate model used in this paper has an update that includes modification to Cloud Condensation Nuclei (CCN) density and cloud droplet effective radius, following the work of Sagoo et al. (2013) and Kiehl and Shields (2013). This update increases higher latitude temperatures without significantly changing tropical temperatures, thereby reducing the pole-to-equator temperature gradient, and better aligning higher latitude temperatures with proxy observations. This update has been verified to be effective under a range of climate conditions, including hot, cool, and icehouse conditions, as well as under pre-industrial boundary conditions. As a result, it is suitable for application throughout the Phanerozoic. In addition, other internal model parameters were tuned, following Irvine et al. (2013). The ocean barotropic flow solver requires all islands in the paleogeography to be manually defined, to allow non-zero flow through ocean gateways. Although Antarctica was defined as an island in the Valdes et al. (2021) post-Eocene simulations, no other islands were defined. For the simulations in this paper, all islands were defined through the Phanerozoic.  A smoothing function was applied in the atmosphere and ocean to avoid gridpoint noise that develops slowly in very long simulations.  In the Valdes et al simulations, the bare-soil albedo is a uniform constant, whereas in these simulations the bare-soil albedo is calculated as a function of the soil carbon content.   tfke only  In the Valdes et al simulations, the atmospheric CO2 is consistent with that of Foster et al (2017).  In these simulations, the atmospheric CO2 was modified in the late Cretaceous and Cenozoic to be consistent with the CO2 record of Rae et al (2021).   tfks only  In the Valdes et al simulations, the atmospheric CO2 is consistent with that of Foster et al (2017).  In these simulations, the atmospheric CO2 was modified in such a way that the model-predicted global mean surface temperatures were consistent with those of Scotese et al (2021).   Climate variables   You can access the HadCM3L climate outputs from e.g.:   https://www.paleo.bristol.ac.uk/ummodel/data/tfkea/climate/tfkeaa.pdclann.nc   for the tfkea 0Ma simulation, and by analogy for the other simulations.    The link above is formed from: ummodel/data/[EXP]/climate/[EXP][TYPE]cl[SEAS].nc where     EXP is the simulation name (see above)   TYPE can be “a.pc” (atmospheric dynamics variables), “a.pd” (atmospheric physics variables), “a.pi” or “a.pt” (land surface variables), “o.pf” (ocean seasonal variables), “o.pg” (ocean annual variables).   SEAS can be “jan”, “feb” etc. or “djf”, “jja” etc. or “ann”.  Note that TYPE=“o.pg” only exists with SEAS=“ann”.         In Linux, you can script the download of multiple files, see Appendix 2.   Sediments and other derived quantities   You can access the implied geological sediments, and other derived quantities such as bioclimatic-related variables from e.g.:   https://www.paleo.bristol.ac.uk/ummodel/data/tfkea/sed/tfkea_sed.nc     for the tfkea 0Ma simulation, and by analogy for the other simulations.    The link above is formed from: ummodel/data/[EXP]/sed/[EXP]_sed.nc   where      EXP is the simulation name (see above)   Boundary conditions and chronologies   You can access the spatial boundary conditions from e.g.:   https://www.paleo.bristol.ac.uk/ummodel/data/tfkea/inidata/tfkea.qrparm.mask.nc     for the tfkea 0Ma simulation, and by analogy for the other simulations.    The link above is formed from: ummodel/data/[EXP]/inidata/[EXP].[BOUND].nc   where           EXP is the simulation name (see above)            BOUND can be “qrparm.mask” (land-sea mask and river runoff routing), “qrparm.omask” (ocean mask and bathymetry), “qrparm.orog” (topography and gravity wave-drag parameters), “qrparm.soil” (soil parameters).       The CO2 values (in ppmv, column 3) and dates (in Ma, column 2) for each simulation are available in the following locations/files:   texy* = Table 2 of Valdes et al (2021), column “CO2 for the smooth CO2”   texp* = Table 2 of Valdes et al (2021), column “CO2 for the Foster CO2”   tfke* = https://www.paleo.bristol.ac.uk/~ggdjl/climate_data/co2_all_03_nt.dat   tfks* = https://www.paleo.bristol.ac.uk/~ggdjl/climate_data/co2_all_04_nt.dat   References   Foster, G.L., Royer, D.L. ,and Lunt, D.J., Future climate forcing potentially without precedent in the last 420 million years. Nature Communications, 8, 14845 doi: 10.1038/ncomms14845, 2017.   P. J. Irvine, L. J. Gregoire, D. J. Lunt, P. J. Valdes, An efficient method to generate a perturbed parameter ensemble of a fully coupled AOGCM without flux-adjustment. Geosci. Model Dev. 6, 1447–1462 (2013). doi:10.5194/gmd-6-1447-2013   Judd, E.J., Tierney, J.E., Lunt, D.J., Montanez, I.P., Huber, B.T., Wing, S.L., Valdes, P.J., A 485-million-year history of Earth’s surface temperature, Science, 385,eadk3705(2024). doi:10.1126/science.adk3705   J. T. Kiehl, C. A. Shields, Sensitivity of the Palaeocene-Eocene Thermal Maximum climate to cloud properties. Philos. Trans. Soc. A. 371, 20130093 (2013). doi:10.1098/rsta.2013.0093   Malanoski, C.M., Farnsworth, A., Lunt, D.J., Valdes, P.J., Saupe, E.E., Climate change is an important predictor of extinction risk on macroevolutionary timescales, Science, 383, 1130-1134, 2024. DOI:10.1126/science.adj5763   Rae, James W.B., Zhang, Yi Ge, Liu, Xiaoqing, Foster, Gavin L., Stoll, Heather M. and Whiteford, Ross D.M. (2021) Atmospheric CO2 over the past 66 million years from marine archives. Annual Review of Earth and Planetary Sciences, 49, 609-641. (doi:10.1146/annurev-earth-082420-063026).   N. Sagoo, P. Valdes, R. Flecker, L. J. Gregoire, The Early Eocene equable climate problem: Can perturbations of climate model parameters identify possible solutions? Philos. Trans. R. Soc. A. 371, 20130123 (2013). doi:10.1098/rsta.2013.0123   Scotese, CR, Song, H, Mills, BJW et al. (1 more author) (2021) Phanerozoic Paleotemperatures: The Earth’s Changing Climate during the Last 540 million years. Earth-Science Reviews, 215. 103503. ISSN 0012-8252 https://doi.org/10.1016/j.earscirev.2021.103503.   Valdes, P. J., Scotese, C. R., and Lunt, D. J.: Deep ocean temperatures through time, Clim. Past, 17, 1483–1506, https://doi.org/10.5194/cp-17-1483-2021, 2021.   Appendix 1   Here is a table including the simulations listed above, plus some other (unpublished) simulations.  I think this is all correct, but I have not double-checked, so please use with caution (and some I haven’t checked at all yet, marked with a “?”).  There are some runs in addition to the ones listed below, but I haven’t added them yet note to Dan – see document Scotese_runs.docx.  In addition, many of them are not all published, and some may not be fully spun up, so please do get in contact before using them:                                                                                                          “puma” name [1]       “movie” name [2]       CO2       solar constant       model version [3]       initialised from       run by       Benchmark publication       Other publications [4]                                                                                                   texs,texx       noco2,noco2a       1x PI       fixed       ?       ?       PJV                                 texv,texv1       solar,solara       1x PI       varying       ?       ?       PJV               Judd et al (2024)                 texz,texz1       2co2,2co2a       2x PI       varying       ?       ?       PJV               Judd et al (2024), Malanoski et al (2024) [Model 4?]                 teya,teya1       4co2,4co2a       4x PI       varying       ?       ?       PJV               Judd et al (2024), Malanoski et al (2024) [Model 5?]                 tex[f-j],texy       spinup, spinupa       Valdes “smooth”       varying       Vn1a       ?       PJV       Valdes et al (2021)       Judd et al (2024)                 tex[p-q]       02       Foster       varying       Vn1b       ?       PJV       Valdes et al (2021)       Judd et al (2024), Malanoski et al (2024) [Model 3?]                 teyd,teyd1       03,03a       Foster       varying       Vn2a       texp       PJV                                 teye       04       Foster       varying       Vn2b       teyd1       PJV               Malanoski et al (2024) [Model 2]                 tfgw       n/a       Foster       varying       Vn2c       teye       DJL               Judd et al (2024)                 tfja       n/a       Foster/Rae       varying       Vn2d       tfgw       DJL                                 tfke       scotese_07       Foster/Rae       varying       Vn2d       tfja       DJL       Lunt et al (in prep)       Judd et al (2024), Malanoski et al (2024) [Model 1]                 tfks       scotese_08       Scotese       varying       Vn2d       tfke       DJL       Lunt et al (in prep)       Judd et al (2024)                 xqbp               Scotese       varying       Vn2d       tfks       TYC                           [1] PUMA refers to the “Providing Unified Model Access” service.  If two names are listed, then the second is initialised from the end of the first, is therefore more spun-up, and is usually the most appropriate to use.  If accessing model outputs in netcdf format using the instructions above, then this is the experiment name to use.   [2] access a full list of simulations, and some standard plots, from: https://www.paleo.bristol.ac.uk/ummodel/scripts/html_bridge/scotese_[movie name].html   [3] See Lunt et al (in prep) for what these actually mean.   [4] This list is far from complete!   Appendix 2   See below for an example linux script to automate the download of files.  The following script will download all the tfke annual and djf data, for the atmospheric physics (a.pd) and ocean seasonal (o.pf) files.  Note that I think it only works with ksh.  It uses the ‘curl’ command to get the files.    #!/bin/ksh  # exp is the ensemble identifier  exp=tfke  # set up the loop over all simulations  expa=${exp}  expb=`sed 's/./\\U&amp;/4' &lt;&lt;&lt; \"${expa}\"`  expc=`sed 's/./\\U&amp;/3' &lt;&lt;&lt; \"${expa}\"`  expd=`sed 's/./\\U&amp;/3' &lt;&lt;&lt; \"${expb}\"`  expe=`sed 's/./\\U&amp;/2' &lt;&lt;&lt; \"${expa}\"`  expids=\"${expa} ${expb} ${expc} ${expd} ${expe}\"  my_loop={a..z}  # loop over the simulations  for expid in ${expids} ; do  if [ \"$expid\" = ${expe} ] ; then        my_loop={a..e}  fi  for ext in ${my_loop} ; do  exp=${expid}${ext}  # loop over the different file types    for type in a.pd o.pf ; do      for seas in ann djf ; do           # now finally get the file:        filename=${exp}${type}cl${seas}.nc        url=\"https://www.paleo.bristol.ac.uk/ummodel/data/${exp}/climate/${filename}\"        echo ${url}        curl -k -o ${filename} ${url}      done    done  done  done  exit   ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_user_notes/Accessing_scotese/",
        "teaser": null
      },{
        "title": "CMIP7 ancillaries",
        "excerpt":"  Text to be written on the CMIP7 ancillaries.  ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_user_notes/CMIP7_ancillaries/",
        "teaser": null
      },{
        "title": "CMIP7 model",
        "excerpt":"  Text to be written on the CMIP7 model.  ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_user_notes/CMIP7_model/",
        "teaser": null
      },{
        "title": "CMIP7 simulations",
        "excerpt":"  Text to be written on the CMIP7 simulations.  ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_user_notes/CMIP7_simulations/",
        "teaser": null
      },{
        "title": "Collaborations",
        "excerpt":"    Collaborations with Scotese simulations   Accessing Scotese data  ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_user_notes/Collaborations/",
        "teaser": null
      },{
        "title": "Collaborations with Scotese simulations",
        "excerpt":"    The purpose of this file is to document collaborations associated with BRIDGE simulations, in particular the “Scotese” simulations carried out by Dan (and earlier simulations by Paul).   Usually we are very happy to share simulations, but would require that we (The person who carried out the simulation, the project PI, and the Bristol person who is the primary contact) are included as co-authors in at least the first paper they publish that uses the simulations, and are included in the scientific discussions.   Information on the simulations   See this document for details of the simulations and naming convention of the Scotese simulations   Alex’s Getech simulations:  tfgs = Getech paleogeogs (to 300 Ma), but with CO2 from tfke.  Same physics as tfke.  10 Cretaceous stages currently missing.   Collaborations:                                                                          Names       Institution       Work       Simulations       Paper status                 Emily Judd and Jess Tierney       Arizona University       Phantastic temperature curve       texp1, texz1, teya1, texv1, texy, tfgw, tfke       Published                 Yongyun Hu       Peking University       Ocean circulation       scotese_spinupa, tfja       Published (without us!)                 Mattias Green       Bangor University       Paleo tidal mixing       tfke       Paper submitted                 Cooper Malanoski (cooper.malanoski@wolfson.ox.ac.uk). Erin’s student/post-doc. (Alex F)       Oxford       Phanerozoic extinction velocity       tfke       Published.                 Jon Richey (jdrichey@ucdavis.edu)       UC Davis       Ecological Plant modelling       tfks (TBC)       in prep                 Wolf Dummann and Jens Herrle       Frankfurt University       OAE2 termination       tfke+tfks       in prep                 Barry Lomax, Mathew Kent (Alex F)       Nottingham University       Geocarb CO2 modelling       tfke+tfks       In prep                 Erin Saupe - Various       Oxford       Various. Playing around with data atm.       tfke+tfks       In prep.                 Emma Dunne       FAU       Niche modelling for Sauropods       tfke/tfks/tfgs       In prep.                 Lewis Jones       Vigo       Niche modelling – Corals &amp; biogeography (Koppen climate classification of Phanerozioc)       tfke/tfks/tfgs       In prep.                 JORGE GARCÍA GIRÓN &amp; Ale Chiarenza       Vigo       dinosaurian megaherbivores       tfke/tfks/tfgs       In prep.                 William J Matthaeus willmatt@udel.edu       Trinity College Dublin       paleo-ecosystem simulations using Paleo-BGC for the Triassic-Jurassic.       tfks/tfke       In prep.                 Zoe Dennehy-Carr and Joy Singarayer.  z.h.dennehy-carr@pgr.reading.ac.uk       Reading       Miocene biogeographical modelling                                 Ana Paiva and Pedro Godoy       Universidade de São Paulo, Brazil       The role of climate on the emergence of giant caimaninae from the miocene western amazonian region       tfgs       Published                 Roger Benson       Oxford       Marine animal diversity across latitudinal and temperature gradients during the Phanerozoic       tfks       Submitted, in review                 James Hansford       The Zoological Society of London       Crocodylomorph.  riassic, Jurassic, Cretaceous, Palaeogene, Neogene, Quaternary       Tfks,tfke       Sent data                 Alex Pohl       Dijon, Bourgogne       Genie, FOAM       Tfks,tfke       Submitted, in review                 Tom Hearing/Mark Williams/Tom Green       Leicester       Cambrian       Tfks,tfke       Comments on paper                 Jianming Qin       China University of Geosciences, Beijing       Cretaceous       Tfks,tfke       Sent data (via Chenmin)                 Davide Foffa       Birmingham       pterosauromorph climate       Tfks,tfke       submitted                 Niklas Werner       ETH       climate multistabililty and carbon cycling over the course of the Phanerozoic       Tfks,tfke       Sent simulation doc                 Alexis Balembois       Bourgogne, Dijon       marine biodiversity and the niche-environment interaction through deep time       Tfks,tfke       submitted                 Alexandros Pantelides       UCL?       Paleobiology PhD student, currently working with Alfio A.Chiarenza and Phillip Mannion on data related to the Campanian-Maastrichtian transition       Tfks,tfke                         Aradhna Tripati and Randy Flores       UCLA       T-Rex model-data comparisons       sent access document                         Olivia Graham       Bristol       Cretaceous model-data comparisons       Seb sent data                         Erin Saupe       Oxford       7Ma - 0Ma spatiotemporally modified to 1deg resolution every 0.5 Ma       tfke series       In prep.          ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_user_notes/Collaborations_scotese/",
        "teaser": null
      },{
        "title": "Documentation for clustersubmit",
        "excerpt":"  Documentation for clustersubmit  Introduction   clustersubmit is the main script that we use to submit UM4.5 (HadCM3, FAMOUS etc.) jobs to our HPC machines. It has evolved from a script called umsubmit which is distributed with the original code from the Met Office. It has been modified and extended frequently and is now a complex code. It has occasionally had major clean-ups, but further additions end up making it a rather untidy and only semi-structured script.   The umui database stores all of the information about a simulation. When the process button is pressed, the umui creates a series of files in the $HOME/umui_jobs/expt_name folder which contains all of the information needed to run the model. These files need to be copied to the HPC.  clustersubmit then takes these files, makes a unique copy in the umui_runs folder (changing some parameters), and submits the UM main script to run on the machine. clustersubmit has gradually become linked to the BRIDGE setup and is not especially transferrable to other machines and setups.   One of the key roles of clustersubmit is to allow the job in the umui to be independent of the target HPC machine. This is achieved by keeping to some common naming conventions within the umui. In the umui, folder and file locations are referred to using standard location names (such as /home/swsvalde or /home/username). These are then converted by clustersubmit to the appropriate local folder name on the relevant HPC machine     A second role of clustersubmit is to swap between compile jobs, new run jobs, and continuation runs without the need to make any changes in the umui itself. In general, it makes life a lot simpler and that the copy of the job within the umui is always the compile option.   A third role of clustersubmit is to change the run time and number of processors, depending on the machine and queue being used. Again, this avoids the need to change these within the umui itself.   clustersubmit has also evolved to do a few other things too.   Example usage   (a)    Compile job:   clustersubmit -c y -s y -q cpu -r bc4 -P abcdef expt_name   (b)    New simulation:   clustersubmit -c n -s y -a y -q veryshort -r bc4 -P abcdef -p 7x4 expt_name   (c)     Continuation simulation on bluepebble:   clustersubmit -c y -s y -a y -q compute -r bp14 -P abcdef -p 6x4 expt_name   Configuration File   It is sometimes useful to set some standard defaults for the machine being used. This can be done by creating a file called: $HOME/.um/clustersubmit.conf.   Typical options are shown for a typical bluepebble configuration:   cores_ns=”6”  cores_ew=”4”  nomail=”y”  notransfer=”y”  rhost=”bp14”  queue=”compute”  account=”GEOG015942”   Typical options are shown for a typical bluecrystal configuration:   cores_ns=”7”  cores_ew=”4”  nomail=”y”  notransfer=”y”  rhost=”bc4”  queue=”cpu”  account=”GEOG015942”   Argument List                  Name       Description       Valid Options       Default                       -expt       Experiment name       Any       None. Compulsory                 -r       The remote machine that will run the simulation       A number of short names for clusters. See note 1 for full list.       None Compulsory                 -q       The queue to submit the job to. The name will depend on the machine. The queue name will also often impact on the default run time.       See note 2 for a list of available queues       None. Compulsory                 -P       Account name       Adds user account for job       Currently needed for bluecrystal and bluepebble. Can be set as a default using the file $HOME/.um/clustersubmit.conf                 -p       Number of cores, in the format NSxEW       Any but total core number must equal size of node (currently 28 cores on bluecrystalp4, 24 cores on bluepebble)       Optional. If not specified, will take value from umui job. Defaults can be set in file $HOME/.um/clustersubmit.conf file                 -g       As -p but without any check on total core number.                                 -w       Wall time       Format is: 24:0:0 (ie. 24 hrs, 0 min, 0 secs) or 14-0:0:0 (i.e. 14 days)       Optional. If not specified, then maximum for the queue specified.                 -u       Username       Any       Optional: default is the same user as submitter                 -F       Force submission       Clustersubmit will check to see if there is already a job running with same name       Optional: Default = n, Option=y                 -n       Email output       Umui jobs can email outputs to user. This can override options       Optional: Default: same as in umui, option=y                 -e       Create ensemble       It is possible to merge a number of umui jobs into a single multnode job. This can sometimes be more       Optional: Default=n, option=y                 -S       Short hand for the best continuation run       Should be used for a continuation run, after compilation       Optional: Default=n, option=y  If y, then the same as:  -c y -s y -a y                 -C       Short hand for the best settings for a compile job       Should be used for compile job only       Optional: Default=n, option=y  If y, then the same as:  -c y -s y                 -A       Short hand for new run, after compilation       Should be used for a new run, after compilation       Optional: Default=n, option=y  If y, then the same as:  -c n -s y -a y                 -a       Change compilation       This changes the job from a compile job to non-compile or vice versa.       Optional: Default=n (no change) option=y (change setting)                 -c       New or continuation run       Changes settings to make it a new run, or continuation run       Optional: Default=n (new run)  option=y (continuation run)                 -l       Write data to local disk       On some machines, the nodes had local disks which are a lot faster than networked disks.       Optional: Default=n  The option=y is currently not used because none of the machines have local disk.                 -m       Rerun the reconfiguration       This is an unusual option. See Note 3 for full explanation       Optional: Default=n, option=y                 -s       Submit job to queue       This is the normal option but could just create the umui_runs folder       Optional: Default=y, option=n                 -f       Copy umui_job files to HPC machine       We used to submit jobs from puma and it was useful to copy the umui_job.       NO longer used. We can no longer submit jobs from puma due to security issues.                 -d       Debug       This print additional information to help debugging       Optional: Default=n, option=y                 -v       Verbose       More output       Optional: Default=n, option=y                 -V or -h -or -?       Version       Prints some information about the script       Optional: No inputs           Note 1: HPC Machine Names                  Clustersubmit name       Full Machine Name       Description                       CURRENT MACHINES                                 bc4       bc4login.acrc.bris.ac.uk       Latest, fourth bluecrystal machine                 bc4login1  bc4login2  bc4login3  bc4login4       bc4login1.acrc.bris.ac.uk  bc4login2.acrc.bris.ac.uk  bc4login3.acrc.bris.ac.uk  bc4login4.acrc.bris.ac.uk       Submitting to bc4 would submit to a general pool of 4 machines. Occasionally, there are problems with this system so it is useful to be able to submit to specific machine.                 bp1       bp1-login01.acrc.bris.ac.uk       Bluepebble HPC machine, using the generic head node                 bp14       bp1-login04.acrc.bris.ac.uk       Bluepebble HPC machine, using the BRIDGE head node                                                   LEGACY MACHINES                                 quest-hpc  quest       quest-hpc.bris.ac.uk       Old quest machine which was a small clusters machine                 Ormen       ormen.ggy.bris.ac.uk       Small predecessor of quest machine                 babyblue  bc  bluecrystal  bluecrystalp1       bluecrystalp1.bris.ac.uk       The first bluecrystal machine                 bigblue  bigbluecrystal  bluecrystalp2       bluecrystalp2.bris.ac.uk       The second bluecrystal machine                 newblue  bluecrystalp3       bluecrystalp2.acrc.bris.ac.uk       The third bluecrsytal machine                 newblue1  newblue2  newblue3  newblue4       newblue1.acrc.bris.ac.uk  newblue2.acrc.bris.ac.uk  newblue3.acrc.bris.ac.uk  newblue4.acrc.bris.ac.uk       Submitting to newblue would submit to a general pool of 4 machines. Occasionall, there were problems with this system so it was useful to be able to submit to specific machine.           Note 2: Queue Names   On bluecrystalp4:                  Queue Name       Characteristics                       cpu       Maximum 14 days run time                 test       Maximum 1 hour run time                 veryshort       Maximum 6 hour run time                 bridge       Maximum 14 days run time. Limited number of nodes available. Available to selected users only.                 paleo       Maximum 14 days run time. Limited number of nodes available. Available to selected users only.           On bluepebble:                  Queue Name       Characteristics                       compute       Maximum 14 days run time                 test       Maximum 1 hour run time                 short       Maximum 3 days run time                 djl       Maximum 14 days run time. Limited number of nodes available. Available to selected users only.                 dmm       Maximum 14 days run time. Limited number of nodes available. Available to selected users only.           Note 3: The -m option   When starting a new model simulation, before the model starts we need to reconfigure the input dump files. This step takes the input dump files, and writes out new dump files typically called $DATAW/$RUNID.astart and $DATAW/$RUNID.ostart. On some occasions, the atmosphere dump reconfiguration crashes. This mostly happens when changing land sea mask but will happen on other occasions too. The output dump file ($RUNDIR.astart) is created but not complete. Sometimes, reconfiguration will work if you re-run the reconfiguration, but starting from the incomplete output dump file ($RUNDIR.astart) and writing out a new dump file (e.g. $RUNDIR.astart1). If you select the (-m y) option, this will all be done automatically.   Note 4: Path translation   Clustersubmit will take folder names from the umui job, and translate a few standard folder names to the specific locations on the relevant machines. This allows you to use universal folder names in the umui and these do not have to be changed depending on the target machine. Currently the folders which are automatically translated are:                  Folder in umui       Folder on bluecrystal       Folder on bluepebble                       /home/swsvalde       /mnt/storage/private/bridge/swsvalde       /bp1/geog-tropical/users/swsvalde                 /home/username  $^*$       /user/name/username       /user/home/username                 ~username1 $^*$       /user/name/username1       /user/name/username1           $^*$ Where username is the name of the user running the simulation and username1 is the name of the owner of the folder   ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_user_notes/Documentation_for_clustersubmit/",
        "teaser": null
      },{
        "title": "Getting started with HadCM3",
        "excerpt":"    The starting point for this document was Paul’s notes. This itself was originally written as a guide for our undergraduate students who were carrying out dissertations using HadCM3.  You may also be interested to look at Nils’s notes   Introduction   This document describes some of the aspects of using the Hadley Centre model HadCM3 and its variants (e.g., FAMOUS) on the BRIDGE servers and the University of Bristol’s HPC machines (bluecrystal and bluepebble). The Hadley Centre model is also known as the Unified Model (UM) which refers to the unification of the model for weather and climate forecasting (the weather forecast model normally uses much higher resolution that the climate version, but it is the same code base). HadCM3 corresponds to version 4.5.1 of the UM (FAMOUS is 4.5.3).   In practice, it takes a lot of time to build experience with all aspects of the system. This document is just a start, but the aim is to gradually expand the content until it is a relatively complete description of the complete system.   Unfortunately, computing platforms and software are always changing, and it is almost certain that some aspects of this document are out-of-date. It is also a developing document, and the aim is to gradually expand it. Therefore it is probably better to always access the online version, rather than having your own copy.   Obtaining Accounts   We use a variety of different computers for running and processing climate model outputs and the first task is to obtain user accounts. Unfortunately, this is always changing so some of this information is out-of-date but it will give you some guidance.   (a) BRIDGE servers. These are used for most day-to-day analysis of model simulations. We have a number of machines, called after geological periods (eocene.ggy.bris.ac.uk, triassic.ggy.bris.ac.uk, silurian.ggy.bris.ac.uk, anthropocene.ggy.bris.ac.uk). To get an account on these machines, please contact your supervisor/PI.   (b) Bluecrystal phase4 and bluepebble. These are our main high-performance computers on which we run climate model simulations. They consist of “login nodes” and many “computer nodes”. The login nodes are called: bc4login.acrc.bris.ac.uk and bp1-login04.acrc.bris.ac.uk. To get an account on these machines, https://www.acrc.bris.ac.uk/login-area/apply.cgi .  Under “Project details” choose “Join an existing project” and give the code (provided by supervisor/PI).  Under “preferred log-in shell” choose bash.  In the box for additional info, you can just state “HadCM3 user”. NOTE: Also specify that you want an account on bluecrystal as well as bluepebble. The default is bluepebble only.   (c) For bluepebble only, You may also need to email them because you need to ask them to create a folder: /bp1/geog-tropical/users/(your username). Also ask to be added to the s-tropical group. Cc p.j.valdes@bristol.ac.uk on your email since they need to confirm additions.   (d) Puma2.  ”puma2” is the machine that holds a database of (almost) all Met Office Unified Model (UM) climate simulations ever carried out in universities in the UK.  It is also the machine from which we set up and submit simulations.  puma2 is now part of the Archer national computing resources. To get access to puma, you need to have an account on archer2. Instructions for access the system are here: https://cms.ncas.ac.uk/puma2/   I would strongly recommend that you choose the same username on puma/archer as at Bristol. It makes life simpler.   In order to access the system, you need to create a ssh-key from one of our servers. The new system allows multiple such keys. I would suggest you do this on bluecrystal but also on our BRIDGE servers. To create the key, on bluecrystal and/or BRIDGE server type:   ssh-keygen -t rsa -f ~/.ssh/id_rsa_puma2   The resulting key needs to be sent to archer, following the instructions in the NCAS website above.   (e) You also need access to our webpage server. Go to: https://www.paleo.bristol.ac.uk/.   This gives you access to all of our model simulations. This is almost overwhelming since over the last 30 years we have performed about 50000 simulations!!!  More details about the web page can be found here: https://www.paleo.bristol.ac.uk/ummodel/scripts/papers/Using_BRIDGE_webpages.pdf   There are also some help pages on our BRIDGE wiki (note that you will need to be on the university network/VPN to access this). See: https://www.paleo.bristol.ac.uk/wiki/bridge/   The Model Description   This paper is a description of the model, HadCM3:   https://www.geosci-model-dev.net/10/3715/2017/gmd-10-3715-2017.html   Read this paper!  It will help you understand the various “flavours” of model that can be used, and their strengths and weaknesses.    The original Met Office documentation for the model is also available.  I wouldn’t expect you to read all of this (!), but it is good to know where it is:   Old location: http://cms.ncas.ac.uk/wiki/Docs/MetOfficeDocs New location: https://www.paleo.bristol.ac.uk/UM_Docs/UM_Technical_Documents/   See in particular document 070 “Specification of ancillary files” which describes how the boundary conditions for the model were originally developed – this will be useful if you come to change boundary conditions yourself.   Learning Linux   Once you have an account on the university supercomputer (which you will only be able to log in to if you are on a UoB computer, or on the UoB VPN; see Appendix A, Working from Home) you can start learning some Linux.  Linux is an “operating system”, a bit like Windows, but it less “point and click” than Windows and is much more powerful and efficient in term of automating tasks and manipulating files.  All serious computer programmers use Linux!    First of all, you will need to log into your account on the machine you will be using.  Logging on to Linux servers is done through a text (command line) interface called SSH. You will still be able to get Gui (graphical user interface, i.e., windows-type) programs to display as well through an environment called X11. The programs ‘PuTTY’ (the SSH client) and ‘Xming’ (the X11 environment for Windows) should already be installed on your UOB PC.    If not, you could try logging into the student remote desktop, instead of directly via your PC:   https://www.bristol.ac.uk/it-services/advice/homeusers/remote/studentdesktop   (See Appendix A on working from home).   However, the version of Xming on the standard UoB machines does not always work correctly.  As such, you will first need to install the free Xming package that can be found at:   https://sourceforge.net/projects/xming/files/Xming/6.9.0.31/Xming-6-9-0-31-setup.exe/download also download and install the Xming fonts:   https://sourceforge.net/projects/xming/files/Xming-fonts/7.7.0.10/Xming-fonts-7-7-0-10-setup.exe/download   First start Xming running from the version you just installed. If this is running correctly, the icon will appear on the right of the windows taskbar. Then open PuTTY (via ‘Start &gt; All Programs &gt; PuTTY’). Fill in the host machine name on the first screen: bc4login.acrc.bris.ac.uk. To view windows sent from the host screen, you need to set up ‘forwarding’. On the left click the ‘+’ symbol next to SSH, then select X11. Tick the box to ’Enable X11 forwarding’.  Also on the left-hand menu, click on ‘Colours’ and put a tick in the box next to ‘Use system colours’.  Then click Open at the bottom of the window. When prompted enter your username. You will have been sent an email of these when you registered on the ACRC webpage. Remember to use the correct password for the machine you are using.   Once you have logged in, you will automatically be in your ‘home’ directory, and you should see the command-line prompt.   Linux requires commands to be typed at the command line (followed by the Return key). An example is ls which will bring up a listing of all the files and folders in the current directory. At the moment, you will have no files, so this command will produce no result. Before you start installing and running the UM, it is important to get used to some simple Linux commands. Work through ‘Tutorial 1’ here: http://www.ee.surrey.ac.uk/Teaching/Unix/ , and ensure that you are happy with listing, making, and moving between directories. Also try removing them (rmdir DIRECTORY_NAME).   There are many good online Linux courses, including some interactive ones, such as: https://linuxsurvival.com/ .   A particularly recommended course is: https://www.netacad.com/campaign/linux-unhatched3   Before going any further, try these online courses until you feel that you are confident using Linux.  In particular, make sure that you can write and edit text files using emacs, move around your directory structures, copy files, move files, and delete files.   Setting up your Linux environment   Now that you are familiar with Linux, you can finish setting up access to your accounts. You only need to do this ONCE. It is important that you follow the instructions precisely and in the order that they are listed. If you are not using bluepebble, skip all commands related to it.   WARNING: The script setup_system overwrites a number of existing files. If you are a new user, this is correct. If you are an existing user, you may wish to avoid using the script but you might want to look at what the script does and mimic it.   One of the key things is to set up ssh keys so that we can move files around between systems without the need for a password. We do this for all machines within the University of Bristol domain. It is very important that you follow these instructions precisely. When you have completed the bluecrystal/bluepebble/eocene ssh key setups, test to see if it works by trying to logon from one machine to another (e.g. from eocene type: ssh bc4). If successful, then you will not need a password.   These are the commands for different machines, to be done in the following order:   (a) bluecrystal   Login to bluecrystal (bc4login.acrc.bris.ac.uk). Standard folder and paths can then be created by typing:   ~ggpjv/swsvalde/etc/setup_system   Press return (default yes) for all questions.   This sets ups all the relevant files, paths and directories that are required to run the UM. It also creates a number of default files (e.g. .profile, .bashrc) which as you become more knowledgeable, you may want to edit. It also includes setting up short machine names for transferring files between machines. Specifically, bc4login.acrc.bris.ac.uk becomes bc4, bp1-login04.acrc.bris.ac.uk becomes bp14, and all of the BRIDGE servers can be used as their short name (i.e., eocene rather than eocene.ggy.bris.ac.uk). See $HOME/.ssh/config for full list of short names.   ssh keys are setup by:  cd $HOME/.ssh ssh-keygen -t rsa -b 2048 -f ~/.ssh/id_rsa  Press return for all questions (DO NOT ENTER A PASSPHRASE).  chmod 400 ~/.ssh/id_rsa cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys ssh-copy-id -i ~/.ssh/id_rsa bp14 ssh-copy-id -i ~/.ssh/id_rsa eocene   (b) bluepebble   Login to bluepebble (bp1-login04.acrc.bris.ac.uk ). Standard folder and paths can then be created by typing:   ~ggpjv/swsvalde/etc/setup_system   Press return (default yes) for all questions.   The script does a similar role to that on bluecrystal, but folder locations are different.   Setting up ssh keys is similar:  cd $HOME/.ssh ssh-keygen -t rsa -b 2048 -f ~/.ssh/id_rsa  Press return for all questions (DO NOT ENTER A PASSPHRASE).  chmod 400 ~/.ssh_ _id_rsa cat ~/.ssh/_ _id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys ssh-copy-id -i ~/.ssh/id_rsa bc4 ssh-copy-id -i ~/.ssh/id_rsa eocene   (c)    eocene   Login to Eocene (eocene.ggy.bris.ac.uk). Standard folder and paths can then be created by typing:   ~swsvalde/etc/setup_system   Press return (default yes) for all questions.   (NOTE the different folder address above)   The script does a similar role to that on bluecrystal, but folder locations are different.   Setting up ssh keys is similar:  cd $HOME/.ssh ssh-keygen -t rsa -b 2048 -f ~/.ssh/id_rsa  Press return for all questions (DO NOT ENTER A PASSPHRASE).  chmod 400 ~/.ssh_ _id_rsa cat ~/.ssh/_ _id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys ssh-copy-id -i ~/.ssh/id_rsa bc4 ssh-copy-id -i ~/.ssh/id_rsa bp14_   (d)   archer2/puma2   You should have already setup the ssh keys as part of the registering process for archer2/puma2. You can add further keys from different machines if you would like. There are also instructions at NCAS for making the logging on puma2 from archer2 password less.   To log into puma2, log into eocene, and then type (you only need to do this once per eocene session):   eval $(ssh-agent); ssh-add ~/.ssh/id_rsa_puma_   you should now be able to log into archer2/puma2 from eocene, by typing:   ssh archer2   On archer2, create a symbolic link:   ln -s /home/n02/n02-puma/username /umui_jobs   then   ssh puma2   Once logged on to puma2, type:   ~swsvalde/etc/setup_system   Press return (default yes) for all questions.   The script does a similar role to that on bluecrystal but folder locations are different.   This has now completed the setup of all of the machines that are required. You only need to do this once.   Advanced Computing Research Centre   You should also make yourself familiar with the ACRC webpages:   https://www.bristol.ac.uk/acrc/high-performance-computing/hpc-documentation-support-and-training/   Overall Summary of running and processing the Unified Model   Introduction   Climate is the average (and other statistics) of weather. The World Meteorological Organisation defines climate as the 30-year statistics of weather, although there is no scientific basis for the use of 30 years. Frequently, researchers working on modern climate choose a shorter period (10 or 20 years). This allows for a more rapid updating of climate to reflect recent changes but means there is more natural variability in the signal (there is a lot of natural, unforced variability of weather and climate). Lovejoy (2013, 2018) suggests that there is a scientific rationale for using 100 years as the averaging period.   A climate model works by simulating day-to-day weather and then treating the resulting output in the same way as real weather. Climate (and other statistics) are calculated from the model simulated weather. The internal time step of the atmosphere (and land surface) model is typically about 30 minutes. The internal time step of the ocean is typically about 1 hour and, in theory, we could output simulated weather at this frequency. However, this would produce a huge amount of output.   In many cases, we do not know the initial state of the climate system, so we often must arbitrarily initialise the state of the atmosphere, ocean, and land surface and then wait until the model reaches a dynamic equilibrium. The atmosphere rapidly comes into equilibrium (within a decade or two). The land surface (especially the deep soil moisture) takes a few decades more. Vegetation can take several centuries to a millennium (boreal forests are slow to grow). The surface ocean responds within a century or two, the deep ocean can take several thousand years (as can ocean biogeochemistry). Hence, we normally run the model for a ‘spinup’ period to allow the model to reach a dynamic equilibrium and then perform averaging (and other statistics) on a final segment.   Overall Process   The introduction above gives an idea of the sort of work that is required in order to complete a climate simulation. It can be summarised in the following steps:           Prepare experiment Prepare an experiment job, using the umui (on puma). The umui is a data base which contains all the information about a particular simulation. The umui creates a 5 letter code which becomes the job name and is used in all following work. In UM terminology, the 5 letter is called the RUNID.            Copy to HPC Once the job is prepared, there is a button on the umui which processes the job. This creates a folder (in $HOME/umui_jobs/RUNID on puma) with a set of files that will control the running of the model, based on the information in the umui database. We must transfer this folder onto the HPC machine where we run the job.            Compile executable On the HPC machine, we first must create an ‘executable’ file for the model itself. We do this be submitting the job to ‘compile’ the code (which is mainly in Fortran) into an executable. It is this executable that we will run. Creating the executable can take between an hour and 12 hours to complete.            Submit simulation Once the executable is created, we can then submit the job to run the model itself. All HPC machines are shared and jobs can be submitted to a number of different queues, depending on the length of the simulation and whether it is a test or full run. Most machines have time limits varying from an hour of cpu time up to 14 days. However, the run may take a long time (up to several months) and will often therefore multiple continuation submissions.            Transfer Data Whilst the model is running, it is outputting the “weather” data and this can rapidly grow to very large quantity of data. Most HPC machines do not have large data storage areas so we need to transfer the data back to our BRIDGE servers.   This is done automatically, following a few setup steps. A script will download all “old” output files (i.e. those no longer needed by the simulation) and will also convert them from UM format to netcdf format. To do this you need to:          Create an entry in our BRIDGE database of UM simulations, and create a copy of the ancillary files (these are files used to setup land sea mask, orography). These two steps are controlled by webpages.   Add the RUNID to a file called $HOME/bin/ftp_sh.bc4.params (or equivalent)           Tidy Experiment and Output When the simulation is finished, you need to download the remaining files, using a script called tidy_expt. You may also want to run another script (fill_gaps_new01) to check that no file is missing.            Create Climate Files Finally, you need to process the files to produce the climate means and other diagnostics. This is also controlled by a webpage.       Prepare the experiment: exploring the Unified Model User Interface   You can now start exploring the model!   Log on to puma. Note that you must have Xming running for the following to work – Xming allows a remote machine to send windows to your desktop.   Type (the &amp; sign puts the user interface in the background, so you can continue to type at the command line):   umui &amp;   A grey Gui should pop up. If it doesn’t then check that Xming and putty are correctly set up.   First, we will find some of the models described in the GMD paper and .  They are all owned by user swsvalde.   Click on: Search –&gt; Filter, and set Owner = swsvalde,USER   Where USER is your username on puma.  This will show your experiments, and those owned by swsvalde.  In ‘umui language’, an ‘Experiment’ is a folder that contains a number of ‘Jobs’.  A Job is the same as a model simulation.   Transferring to the HPC machine   Having processed the experiment, the umui will have created a folder on puma2 called $HOME/umui_jobs/expt_name.   This folder needs to be transferred to the HPC machine. To do this, you need to do one or two copies depending on which machine your id_rsa.puma was created. From this machine, type:   scp -rp archer2:umui_jobs/expt_name ~/umui_jobs   If this machine is not the HPC, then do   scp -rp ~/umui_jobs/expt_name bc4:umui_jobs   (use bc4 for bluecrystal, use bp14 for bluepebble).   You should now have the expt_name folder on the HPC machine.   Submitting the simulation   Now that all of the scripts have been transferred, we need to submit the job. This normally requires two steps. The first step requires to create the executable file from the fortran code. To do this, type:   clustersubmit -C y -r bc4 expt_name   You now have to wait. On bc4, it will take about 6 hours to create the executable. On bp14, it will take about an hour. You will receive an email (either on the machine, or your inbox).   After the executable is completed, you now need to submit the actual simulation. To do this, try:   clustersubmit -c n -s y -a y -q veryshort -r bc4 -p 7x4 expt_name     (if using bc4)   or   clustersubmit -c n -s y -a y -q short -r bp14 -p 6x4 expt_name   (if using bp14)   This submits your job.   Other documentation   Here is documentation for some of the key scripts/processes:   Documentation for clustersubmit   Documentation for ensembles   ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_user_notes/Getting_started_with_HadCM3/",
        "teaser": null
      },{
        "title": "HadCM3 for CMIP7",
        "excerpt":"  CMIP7 simulations   CMIP7 ancillaries   CMIP7 model   ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_user_notes/HadCM3_CMIP7/",
        "teaser": null
      },{
        "title": "HadCM3 Workflow",
        "excerpt":"  HadCM3 Workflow   Introduction   The BRIDGE (Bristol Research Initiative for the Dynamic Global Environment) research group works with collaborators at XTBG (Xishuanbanna Tropical Botanical Garden) use computer models to research past, present and future climate change, investigate the causes of these changes, and the impact on plants and biodiversity. We use plant fossil data combined with computer models of climate and vegetation. Climate models require high performance computing.   Computer climate models work by simulating the day-to-day variations of weather, and then creating the climate by performing statistical analysis of the resulting output. Substantial computing resources are needed to both run the models, and store the “weather” output before it is processed into climate.   HadCM3/HadAM3/HadRM3 Software   We use the Hadley Centre climate model for all of our research. This is a relatively old climate model (developed in 1999) but has the benefit that it is computationally cheap so that we can perform long simulations and multiple sensitivity studies.   The software consists of three major components:   a. The scientific code base is about 500,000 lines of fortran 77 code.   b. Data output and the interface to parallisation library is about 20,000 line of C   c. A relatively complex set of korn shell scripts control the simulation (20,000 lines)   The code requires the mpirun library to be installed   In addition to the Hadley centre, there is also a code base required to convert output data to a common format (netcdf) and then process the output to produce the climate data. This is about another 200,000 lines of code, in a range of languages (C, Fortran, and bash). It also uses the nco and cdo operators (free netcdf processing software). Almost all of this code is single core.   Typical Workflow    To perform a simulation requires the following steps:           Prepare the “job” to be submitted. This uses a software tool called umui which is run on a UK university computer. Although this could also be copied to other servers, there is no requirement to do so. Furthermore, there is benefit in continuing to use one version so that there remains a unique and single database of all simulations. The output from the umui is a set of files which need to be copied onto the HPC machine.            Prepare the input data for the simulation. This typically uses a range of tools, depending on the user and the scientific motivation. This normally is very quick to run. The input data needs to be copied to the HPC machine.            Compile the fortran and c code on the HPC machine            Run the resulting executable. This may take weeks or more to run.            Depending on file storage on the HPC machines, it is likely that data needs to be transferred from the HPC machine to a machine which has significant storage.            The data also needs to be converted from a non-standard format to netcdf (a widely used format for geographical data). We often do this at the same time as transferring data            Once the whole simulation is completed, a set of programs and scripts need to be run to calculate the climate (the average of the weather data and other statistics). The climate output needs to be stored for many years.            Once the climate output has been produced, it is often OK to either delete or archive the weather data. Archiving is best for long simulations where it has taken a lot of effort to produce the data, whereas we some times delete smaller/shorter simulations when it would be simple to rerun the model is further analysis is required.            Scientific analysis and discovery of the climate output. This requires a lot of investigation and the production of many different graphics.       Code Performance   The performance of the model depends on the grid size used to represent the Earth system. It also depends on whether the model represents only the atmosphere or is also coupled to the ocean. If the model includes the ocean, then it is likely that longer simulations are required to allow the ocean to come into equilibrium with the rest of the system.   The following table summarises the computing and disk requirements for a range of different model configurations:                  Model Name       Atmosphere Resolution       Ocean Levels       Typical number cores $^a$       Run Speed $^{b,c}$       Typical length of run       Typical Duration of run $^d$       Total number of core hours       Typical Amount of raw “weather” output       Typical Amount of climate output                       HadCM3       96 longitudes, 73 latitudes,  19 levels       288 longitudes,  144 latitudes, 20 levels       28       100 model years per day       5000 years       7 weeks                                         HadCM3L       96 longitudes, 73 latitudes,  19 levels       96 longitudes,  73 latitudes,  20 levels       28               5000 years                                                 HadAM3       96 longitudes, 73 latitudes,  19 levels               28               100 years                                                 HadAM3-N216       432 longitudes, 325 latitudes,  30 levels               84               100 years                                                 HadRM3_0.44       96 longitudes, 73 latitudes,  19 levels               28               100 years                                                 HadRM3_0.11       96 longitudes, 73 latitudes,  19 levels               28               100 years                                           $^a$ The model parallelises well across cores within the same motherboard. For instance, in the example above, there were two chips (each with 14 cores) on the same motherboard. It is also very flexible and we can run with any number of cores. The parallisation is poorer when running across several nodes and often completely fails to lead to further performance increases. The key influence is the inter-node transfer speed. Machine with faster internal networking (such as infiniband) allow for better parallelisation across nodes.   $^b$ Based on intel xeon chips, but about 5 years old.   $^c$ Run speed is controlled by the clock speed and number of cores, but is also influenced by the memory speed/structure and disk speed (writing output to disk can be a bottleneck)   $^d$ This does not include any time spent queuing. The model can be stopped and restarted at any time and is efficient at restarting so individual steps can be any length.   Number of simulations   Paleoclimate simulations have a number of uncertainties and to fully quantify this uncertainty requires…   ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_user_notes/HadCM3_Workflow/",
        "teaser": null
      },{
        "title": "Nils notes for running HadCM3B",
        "excerpt":"Preliminary steps HadCM3     Get accounts (archer2, puma, bc, bp, bridge servers)   Set up ssh-keys   Start umui (note for ubuntu users: fonts-terminus-otb package needed for proper rendering)   Create new job on puma     Start umui   Search –&gt; Filter: owner            swsvalde: standard configurations of differenct HadCM3B versions                    tdem –&gt; HadAM standard with dyn veg (PI)           tdaa –&gt; HadCM3 with dyn veg (PI)                       USERNAME: my experiments           Experiment –&gt; new: create experiment code (4 letters) with some description   Select reference job (not experiment but job within experiment) and new experiment   Job –&gt; copy: select identifier for job (5th letter in the job code) and description   This creates new job in the new experiment   File –&gt; open read/write: this opens new window in which simulation can be further configured (mods = code modifications compared to vn4.5.1, ancil = boundary conditions, initial conditions, parameters)            “Model Selection –&gt; Sub-Model Independent –&gt; Compilation and Modification”: Select mods and compile options (Modifications for the model –&gt; relevant mods for model updates / bug fixes)                    for compile options use: “Compile and build the executable named below, then stop” is standard (“Run from existing executable” rare alternative, because running new job with existing executable is normally done on different level where it’s faster to update the specifications you want to change than to click through the whole umui configuration gui)           e.g., “Modifications for the model” –&gt; abx0f406 –&gt; change MOSES1 to MOS2.1                       “Model Selection –&gt; Sub-Model Independent –&gt; Ancillary reference time”: Set reference time for boundary conditions (usually 1849-12-1 for PI, as simulations tend to start on Dec 1)       “Model Selection –&gt; Sub-Model Independent –&gt; Starte Date and Run Length Options”: Set start date (this can be a random year for all simulations with fixed orbit, as orbit time is specified somewhere else, typically 1850-12-1; for transient orbit there is option to use offset to have negative years for orbit calculation but still use positive years in output files), and run length (typically 100yr + 1 months for the initial December which exists to still have 100 DJFs in 100 yr simulations)       “Model Selection –&gt; Atmosphere”: Specific Atmosphere:                    “Model Selection –&gt; Atmosphere –&gt; Section by section –&gt; Vegetation” allows configuring some vegetation parameters           “Model Selection –&gt; Atmosphere –&gt; Ancillary and input data files”: boundary conditions           “Model Selection –&gt; Atmosphere –&gt; STASH”: output specification (define diagnostics, i.e., variable, time averaging, usage)           “Model Selection –&gt; Atmosphere –&gt; STASH –&gt; STASH. Specification of Diagnostic requirements –&gt; Diagnostics” –&gt; Load diagnostics to add new variable, then specific time, domain and usage           After modifications run “Diagnostics –&gt; Verify Diagnostics” to check for potential errors                       “Model Selection –&gt; Ocean GCM”: similar to athmosphere       Click “Save”       Click “Process” –&gt; this creates the relevant configuration files           Executable location –&gt; $DATAW   Output –&gt; $DATAM   Exit puma   On ARCHER2: job configuration in “umui_jobs/umui_jobs/JOBNAME”: these are just text files containing the full configuration of the job, that are then used to compile the job   Creating mods     During configuration of add mod name to the list of mods            Select Model Selection –&gt; Sub-Model Independent –&gt; Compilation and Modifications –&gt; Modifications for the model       In Fortran mods, add a line after the existing mods: $MY_UPDATES/MODNAME.mod and set Y/N to Y       Then process job as previously described           $MY_UPDATES refers to ~/um_updates/   In ~/um_updates create new file with “emacs MODNAME.mod” (.mod is not needed and just helps to identify the file as mod, in newest emacs version, its annoying because it is treated like a module file which makes writing the code very annoying)   Structure of a mod file            First line: \t*ID MODNAME Define the modname       Second line: *DECLARE FILENAME Defines in which file of the code deck, the code should be changed (note that for modifications of previous mods, the name of the mode needs to mentioned afterwards, but only the actual .f file needs to be declared here)       Afterwards, three types of modifications are possible:                    *D  FILENAME.LINENUMBER \\n NEWCODE –&gt; Delete the specified number of code in the specified file and replace it by the (potentially multiple lines of) code provided in the following line (after \\n)           *I  FILENAME.LINENUMBER \\n NEWCODE –&gt; Insert NEWCODE after line LINENUMBER in file FILENAME           *B  FILENAME.LINENUMBER \\n NEWCODE –&gt; Insert NEWCODE before line LINENUMBER in file FILENAME                                Example structure of a mod:         *ID CO2_FACTORIZATION_150PPM   *DECLARE PHYSIO7A   *I PHYSIO7A.129 \t\t\t\t   !----------------------------------------------------------------------   ! Set atmospheric CO2 used in MOSES to 150ppm   !----------------------------------------------------------------------         REAL CO2_VEG                 ! CO2 value for factorization \t\t\t                                       PARAMETER(CO2_VEG = 0.000227874) \t\t\t   *D ACN1F405.125        &amp;,               CO2_VEG,CO2_3D,CO2_DIM,L_CO2_INTERACTIVE           Note: Check im browser code deck what line in what file need to be changed (line number correspond to the versio available at https://www.paleo.bristol.ac.uk/UM4.5/UMbrowser/index.html)   Note: Correct inundation is important   Note: For inspiration can look at Paul’s experimental mods in ggpjv/um_updates   Note: For inspiration can look at operational mods in ggpjc/swsvalde/um_updates   Afterwards, check if the mode worked by checking if compile produced any errors and can check if the final code files in dataw/comp_JOBNAME.tar.gz look as intended (sometimes a different mod can change the file in an unexpected way such that the final code doesn’t look as intended)   Copy job to Bristol servers     Log onto eocene   Run eval $(ssh-agent); ssh-add ~/.ssh/id_rsa_puma2   copy first to Eocene by running on Eocene: scp -rp archer2:umui_jobs/umui_jobs/JOBNAME umui_jobs/.   copy from Eocene to BC4 by running on Eocene: scp -rp umui_jobs/JOBNAME bc4:umui_jobs/.   then log onto bc4 with ssh bc4 to continue   Compile job     Run on bc4: clustersubmit -C y JOBNAME   This creates executable   To check if compilation was successful run on bc4: leave_file_errors_02 JOBNAME   Brute force code modifications     Unpack comp_JOBNAME.tar.gz file from dataw into code directly (which should be empty after compile)   Modify fortran files (xxx.f) as needed with emacs and save them   Then run two line to recompile the changed files:            make -f makefile.compile       make -f makefile.link           Note: this procedure does not work if the subroutine is in the standard code deck, because the code directory only contains symlinks to standard files and will not recompile those files   Creating runs without using umui GUI:     Create new job prior to compiling:   Step 1) Sript to copy job files, give new name to experiment, change EXPTID and JOBID in the job files where needed: new_expt_letter OLDJOBID NEWJOBID   Step 2) Modify jobfiles as desired (e.g. change modset in MODS_UM)   Step 3) Compile and run   Create new job from existing executable:   Step 1) Create baseline job with desired configuration (modsets)   Step 2) Run script to create ensembles: create_ensemble   Step 3) Modify namelist parameters (and ancil files if relevant?) in new jobs   Step 4) Run jobs (with clustersubmit?)   Run job     Run on bc4: clustersubmit -c n -s y -a y -q veryshort -r bc4 -p 7x4 -P PROJECTNUMBER JOBNAME   “-c n” –&gt; new run   “-c y” –&gt; continuation   “-q veryshort” : max. 6h runtime   “-q cpu”: max 14d runtime   I don’t remember what -s and -a mean   Machine: “-r bc4”   Configuration for splitting domain: “-p 7x4”   Account: “-P PROJECTNUMBER”   Defaults for machine, configuration, and account can also be set in $HOME/.um/clustersubmit.conf   Supervising running jobs     Checking status of your jobs: myqs1   Executable and logs in $HOME/DUMP2HOLD/um/JOBNAME/dataw/ (astart = atmosphere initial condition, ostart = ocean start condition, pe0-pe27: log from cores, pe0: lead core, thist: save current timestep for restart if model crashes)   Output in $HOME/DUMP2HOLD/um/JOBNAME/datam/ (da = dump, pc/pd/pi/pf/pg = output files for each month, solarorbit = orbit configuration in case of transient orbits)   Checking current state of simulation: “tail xqcra.fort6.pe0”   Checking state of all jobs and used diskspace: “special_where”   You can find your jobid with the following command: squeue -u USERNAME   The normal method to kill a Slurm job is: scancel JOBID   Postprocessing:     Through webinterface   Open https://www.paleo.bristol.ac.uk/web_pages.htm   Click on “Add/Modify List Runs”: enter new job into list of eperiments: if building directly on previous experiment, can use this one to set default values   Click on “Get_boundary_condition_files”: if building directly on previous experiment, can use this one to create symlinks to old experiment) (Note: I’m not sure if this is actually needed at this point, or enough to do it after the run is finished and all files are transferred to silurian, should only work if I copy job files from puma first to eocene and then to bc4 and not if I copy them directly to bc4; in the latter case, it’s likely that it should still work if it’s only added after copying everything onto silurian]   Log onto silurian with “ssh -X USERNAME@silurian.ggy.bris.ac.uk”   create directory “bin” in your home directory (this is only needed once in the beginning)   create file “ftp_sh.bc4.params” (this is only needed once in the beginning)   Add jobname in file “ftp_sh.bc4.params”   There is automatic download script which runs through all users every 4h, downloads files from bc4 onto silurian, and converts them into nc files   For manual download, run “ftp_master -machine bc4 -expt JOBNAME” (this downloads files from bc4 onto silurian and converts them into nc files)   Data can be accessed from eocene through umdata/JOBNAME (umdata is a symlink /home/bridge/swsvalde/umdata, where symlinks to the actual locations of the data are collected, the actual location of the data is selected automatically by the system by searching for the disk with the most available space)   When run is finished, run “tidy_expt -machine bc4 -expt JOBNAME” (this copies all remaining files and converts them to nc files, tar’s and gzip’s the dataw directory such that run could be restarted from those files if needed, and deletes all run files from bc4)   After this, all model output is stored on silurian   Open https://www.paleo.bristol.ac.uk/web_pages.htm   Click on “Run_scripts”, enter jobname, and click on run_scripts   Specify diagnostics that should be run   Click on “Run_Diag”   This creates all files that are available trough the webserver, from eocene they can be accessed through “ummodel/data/JOBNAME” (ummodel is just a symlink to “/home/bridge/swsvalde/ummodel”; not sure how this ultimately works because that disk is too small to carry all runs available on the webserver, the majority has to lie somewhere else)   Progress of the postprocessing scripts can be tracked under https://www.paleo.bristol.ac.uk/ummodel/access/USERNAME_JOBNAME/   Delete all job files from silurian whenever it’s clear that the run is not needed anymore   Note: there is currently no simple way to transfer data from disk to tape, so, normally after cleaning up everything only the data on the webserver is still available from an experiment  ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_user_notes/Nils_notes_for_running_HadCM3B/",
        "teaser": null
      },{
        "title": "Running Ensembles on bluecrystalp4",
        "excerpt":"  Documentation for ensembles   Background   Very often on bluepebble/bluecrystal, we have to queue for some time before the job commences. It is then frustrating if it crashes (e.g. with negative pressure or negative theta) after a relatively short time. The crash can often be easy to sort out but your job goes to the bottom of the queue.   Another problem with the queueing system on bluepebble/bluecrystal is that there is an absolute limit on the number of jobs that can run/queue at the same time (I think it is 40) but there is a larger limit on the total number of nodes (currently 100). The normal resolution of HadCM3 does not efficiently scale beyond 1 node so we cannot make use of the maximum node count.   To solve this problem, we have created the “ensemble script” which can combine several jobs into one bigger job, or can run one job within a larger overall job that can restart the model if it crashes.   Basic Concept   UM version 4.5 (HadCM3 and family) consists of a set of fortran subroutines with a complicated suite of korn shell scripts to support running it. In practice, the complex scripts are quite difficult to change because they all strongly interact with one another. However, ultimately when you submit a job to run there is one overall driving script which runs everything.  Hence to run multiple versions of the model, all you need to do is to create/capture this script for each ensemble member and then find a mechanism to make the set of scripts run on a set of compute nodes. Simplistically, an ensemble script would look like:  # for node in list of nodes ; do   command to run job_N on node  &amp; done # while [ some criteria ] ; do   check to see if criteria satisfied done   where the &amp; gets the job to run in the background and will continue to run until some criteria is met. This structure is pretty much how the new method works.   The script that drives the running of any particular job is created when you submit a job using clustersubmit, and is held in the umui_runs folder (not umui_jobs). It is called qsubmit.bc4loginX. bc4.acrc.priv and it is this script we need to grab (where X is one of the head nodes 1-4).   Step 1  Prepare your ensemble set of jobs, and run them for a few months. Currently the script works best for continuation runs (it will work for new runs too but it will always be less reliable because new jobs are less reliable).   Copy the relevant umui_jobs to bc4/bp14   Step 2  On bluecrystal, create a folder $HOME/ensembles. Also copy some files:  cp ~ggpjv/ensembles/run_scripts_01 \\$HOME/ensembles   cp ~ggpjv/ensembles/master_script_02 \\$HOME/ensembles   cp ~ggpjv/ensembles/normal_resubmit_02 \\$HOME/ensembles   cp ~ggpjv/ensembles/history_script_02 \\$HOME/ensembles  I’m advocating this method currently because I am still learning how best to do this and they may change without notice. Eventually we will have a stable version and these scripts will able to be accessed from some common location. By copying then across, there is no danger that they will change.   Step 3 (assuming that ~ggpjv/swsvalde/bin is in your PATH variable)   Use the script create_ensemble to prepare the required files. Details of the script are below but the simplest use is:   create_ensemble -file xxxxx -expts list_expts   Where xxxxx is a filename which will contain a list of the required unui_runs folders. You should typically keep this to about 6 or 7 characters.   And list_expts is a list of experiments, separated by commas or spaces.   The script creates a file $HOME/ensembles/ensemble_files/xxxxx.dat which contains a list of umui_runs folders.   The script works by submitting each experiment, then deletes the submitted job, but saves the corresponding umui_runs folder by copying it into the $HOME/ensembles/umui_runs folder. It must do this because the $HOME/umui_runs/ folders get deleted. It also edits the qsubmit script to ensure that it correctly picks up node information, and edits the output file name to be .eleave instead of the normal .leave.   Finally it creates the batch file to run the model. This file is called: $HOME/ensembles/xxxxx_batch.   To submit the ensemble type:  \\cd $HOME/ensembles sbatch xxxxx_batch   Step 4  You now need to monitor how it is running. There are a number of tools to help:   (a) check_running xxx   (or simply check_running which will do all files in $HOME/ensembles/ensemble_files).   This creates a list of the status of each simulation within the ensemble file. If xxx is specified, it will do the xxx.dat file from $HOME/ensembles/ensemble_files/ folder. The output produces a list with each row looking like this:   tfed.dat: tfedq: compute139: compute139: 4292608 Mar 12 14:39 tfedqa#pd000006607ja+ tfedqa#pd000006590dc+ Mar 12 09:47  79.31   where first column is ensemble file, second is experiment name, third is the expected node based on those available, fourth is the actual node based on the .eleave file, 5-9 is the size, latest modification time, and name of latest file, 10-13 is the latest file when the last time you called the script, and column 14 is the estimated model speed (years per day) based on the time difference between the two files.   Things to pay attention to are:   (1) That the expected and actual node should be the same. If they are different, something bad has happened and you need to stop the job.   (2) The date of the latest file should be nearly the current time (with one or two minutes). If not then that simulation has crashed. If it is more than 20 mins old, then it had also failed to restart so something more profound has gone wrong. But it may be possible to restart it. See later for solutions.   (3) The model speed should be something appropriate (i.e. about 30-50 model years per day for HadCM3, 80-90 years per day for HadCM3L, and several hundred years per day for FAMOUS). If it is much smaller, it could be because the model is starting, running for a month or two and then crashing, and then repeating this sequence. So a file could look to be new, but overall the model is failing. See later for solutions.   If (2) or (3) show problems, the first thing you should try is to reset the start file by using the restart_manually script (below). For some reason, I have noticed that the phist/thist files are not regularly updated so sometimes the model may try and restart from a much older location and the dump file is missing. This is quite common when restarting an ensemble run. NOTE that there is a time delay when doing this and it can take 20+ minutes before everything restarts so be patient and do not assume there is a problem prematurely!   (b) special_where:  This is a tool I use a lot and is not especially related to ensembles but it is good check on progress of runs. It also checks that downloading is working too.   There are no arguments to this script, just type: special_where   The output is a series of columns for each simulation of the form:   tfefr n   90,484M diiidi pc_no =  2005 pd_no =  1766 pf_no =   699 pg_no =    35 last= tfefra#pd000006631sp+ ggpjv  8266     0 Mar 12 19:25   2nd column = is it running or not (based on looking at the queue so will not think that it is running if part of an ensemble)  3rd column = total space used by experiment in dump2hold  4th column = what has happened to folder since last running script. Codes are n if new, d if number files reduced, s if same, S is same but file is recently created, and i if number of files is increasing. The set of letters correspond to total files, pc, pd, pf, pg and latest pd file.  5th-12th column = number of files of each type  13th column= latest file  14th column = owner  15th column = model speed, based on average across the files in datam (in units of 100x years per day)  16th column = model speed, based on time difference between latest file and previous one.  17th-19th = Date of modification of latest file   (c) edit_phist xxx yyy zzz: This script will reset the phist/thist files to start from a specific dump file. It assumes that the start month was Dec and will only reset to a Dec start date. xxx is the experiment name, yyy is the dump_age_name (i.e. the name after …da), and zzz is the year since start of run. This script (the swsvalde version) is more sophisticated than other versions of this script because it resets all of the contents of the namelist file. This seems safer than only making the minimum modifications of the contents, though it is not clear whether it makes any difference.   In theory, if you just specify the experiment name, it should work out the very latest restart. However, due to variations in the namelist structure, this is not fully reliable so there is an additional script.   (d) restart_manually xxx: This is an extension to the edit_phist script and resets the phist/thist files to the latest available dump file. xxx is the experiment name. It works by finding the most recent dump file in the datam folder. However, to make this work it needs to know what was the start year of the simulation, and the script does not assume it is correctly stored in the phist/thist files. Hence to use this script you need to create a file in $HOME/ensembles/restart_manually_input with lines of the form:   temp 1850  tewza 2850   Where the number indicates the start year, and the 4 letter code means that all experiments starting with the 4 letter code will use this start year, whereas the 5 letter code only refers to the specific simulation.   Solving Problems   The output from the jobs is stored in the normal location ($HOME/um/umui_out) but in files ending .eleave. If the model goes wrong, it will rapidly generate .eleave files every 10-20 minutes.   clean_eleave_files: deletes all of the eleave files except for the latest one for each simulation.   The .eleave files are identical to the normal .leave files so you can hopefully diagnose the problem and correct it. The job will then automatically restart.   Ending the job   The job will not finish automatically. You will need to kill it (or let it timeout). Also, you will find the individual jobs will run at different speeds so you may decide to kill the job before they are all finished. For instance, it is a bit anti-social to be using 10 nodes but only one node is used. But there is no hard and fast rule. It is up to the individual to decide when to kill it.   Bit more ambition   It is possible to start a new simulation when an ensemble member finishes and when there is still time left for the overall ensemble. To do this you must first run create_ensemble:   ` create_ensemble -file temp1 -expt abcde`   Then edit the running ensemble_files/xxxxx.dat file and replace the job that has finished with the job that you want to start which is listed in temp1.dat. HOWEVER, you must be very careful to ensure that you keep the order the same. i.e if job 5 out of 8 has finished, you must replace line 5 and not add the job to the end. Similarly, you must keep the same number (actually you can increase the number of simulations listed but it is pointless. You must not decrease the number).   However, there is an experimental facility (which so far seems to work) where you can create a list of jobs in the file $HOME/ensembles/new_runs_list.dat  then it will work through these when a job finishes.   A little more details of the scripts   run_scripts_01  This script starts the jobs running. The first argument is the umui_runs folder name, and the second is the node to run it on. It copies the relevant $HOME/ensembles/umui_runs folder to $HOME/umui_runs and then starts the job by simply executing the relevant qsubmit script as a background job (this allows the system to move on to the next command).   NOTE that there is a 120 sec time delay in the batch file after starting each job. This was added because there was a weird problem that I could not understand. Sometimes, if the jobs were started too rapidly, the output files (i.e. those in datam) would end up in the wrong simulation folder. I could not work out why but adding the time delay seems to largely cure the problem.   master_script_02  This script loops over the nodes, decides whether it is still running and then resubmits the job if it has crashed. It calls:   (a) normal_resubmit_02: this works out whether the running job has stopped, and if so why has it failed. This script calls quite a few other scripts.   (b) history_script_02: this work out the status of the run at the time of resubmission. In theory it can be used to help get the script to do different things depending on whether it has been resubmitted from this point before. But not very reliable.   If these scripts work out it needs resubmitting then master_script will resubmit.   create_ensemble  This creates the required files, specifically:   (a) creates the umui_runs folder for each experiment within the ensemble by submitting the job using clustersubmit and then copying the umui_runs folder to the ensembles folder.   (b) creates the .dat file for the ensemble which is the last of umui_runs folders   (c) creates the batch file for the job.   A full set of arguments are:                  -e       -expts       -expt )    - this is a list of expts. No default.                          -d       -delete       -new )    - by default, the script will add to an existing .dat file. If -d y, then the .dat file is created from scratch.           -c )    - continuation run (default).If -c n, then will treat then as new runs.                  -f       -file )    - outfile name for .dat file, and also for the batch file.           -p )    - processor usage. Default is 7x4. (but will default to 6x4 for bluepebble)   -q )    - the queue to submit to. Default=cpu, but could be bridge or paleo.   -g)    - groups the experiments into batches of N jobs   ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_user_notes/Running_Ensembles_on_bluecrystalp4/",
        "teaser": null
      },{
        "title": "Standard swsvalde UM Model jobs",
        "excerpt":"  1) tcsy - HadCM3B-M1 - HadCM3B with MOSES1   This job has its original origins from the original release of the PUM, starting around the year 2000. This was modified for running on standard MPP machines but should otherwise be scientifically identical to the original HadCM3-M1 as published in Pope et al and Gordon et al. Over the subsequent 9 years, the core science remained unchanged but a standard structure and naming convention was developed so that it was easy to submit to a range of different machines without the need to make changes within the umui.   In 2009, related to problems with the MOSES2.1 (see later), it was realised that we needed to create standard versions of all model setups. We also needed to benchmark standard versions.                  Name       Date       Description       Impact                       1.b       2009-07-21       Near original as distributed within the PUM (portable UM) system. There are a lot of changes to the paths etc, some changes to updates needed to run on the current machines, small changes to pre-industrial CO2 etc       Before making the small CO2 changes, this was benchmarked against a standard HadCM3 M1 simulation made by the Hadley centre and archived at BADC                 1.c       2010-03-18       Small changes to process count and compilation, addition of automatic resubmission on current computer systems. Changed energy adjustment to MPP fast option and added mods:  ofilter_mpp.mod (improved parallel code),  timerupd_new.mod (timer improvement)  nomsrest (bug fix on mass of atmosphere)       None of the changes should have changed the science. Benchmarked against previous version. No statistically significant changes (mainly focussed on surface temp/precip)                 1.d       2010-08-04       Additional updates (some of which make small changes to science). These are mainly bug fixes or output changes:  atmstep_flush.mod (makes sure output is up-to-date if model crashes)  gancf407.mf77.pjv (bug fixes for MPP machines)  gsm9f406 (compiler fix)  inittime_info (more info if stops for wrong date in dump/umui)  coupledfix_new.mod (sorts out a few GCOM/MPP problems)  gbc0f406 (load balancing for tracers)  medout44.mod (corrects bug in HadCM3L Mediterranean outflow code but OK to include in all versions)  ganbf407.mf77 (fixes divide by zero problem for snow on seaice)  ocn_filt.mf77.pjv (ocean filter bug fix)  ocnstep_print.mod (ocean time stepping output)       Benchmarked against previous version. No statistically significant changes (mainly focussed on surface temp/precip)                 1.e       2013-06       Some further bug fixes. Also changed some options to use optimised MPP code (but not bit reproducible). Updates include:   rssafehs4.4 (real calendar problem fix)  gdr1f406 (name change to LBCs)  dummy (adds dummy routine for missing subroutines)       Benchmarked against previous version. Very small differences, barely statistically significant changes (mainly focussed on surface temp/precip)                 1.f       2013-08       Stopped configuring/using the single level soil moisture ancil since it is not used anyway. Removed the visbeck mod. This reintroduced a bug in the code but made it exactly as the published model. No longer seemed to be necessary to keep.  Also added:  ask1f406: fixes negative sqrt problem  ask6f406: fixes bug in atmos tracer  boundsfix_famous.mod_xcpsa  bounsfix_nompp.mod  boundsfix_vn4.5.mod  (the three above are sorting bounds fix problems)  (these removed the need to coupled_bugs4a)       Benchmarked against previous version. Very small differences, barely statistically significant changes (mainly focussed on surface temp/precip). However, was expecting more from the removal of the visbeck bug. Likely because the tests were relatively short (~100 years)                 1.g       2014-08       Added option to have compiler overrides. This was needed because of new machine. Also turned off spiral coastal adjustment algorithm. No idea why and what it does!!!  Also added:  extendSTASH_SETDIR.mod: increased the size of the character strong that holds the STASHMASTER files. New machine had long pathname.  oceantracerstash.mod: Sorted but if ocean tracers if first additional tracer (beyond temp/salinity) was not tracer 3       Not benchmarked.                 1.h       2021-07       Quite a big tidy up of code, though no major science changes. This included resetting the optimised MPP versions of some options back to the standard version. It was found that the optimised version did not make the model faster (in one case slowed the model) so it seemed better to have the bit reproducible version. Some STASH changes   Added:  long_output_names02.mod (longer file names to simplify extremely long runs)  solar_orbit_real1950.mod: This added a changing orbit to model. It allows different orbits within the same executable. More details of the history of this update can be found in separate document       Not benchmarked                 1.i       2022-10       Big changes to the science and infrastructure. Script update to remove the need for pdksh (pdksh_remove), and to reduce number of needless warning messages (remove_warnings). Also removed archiving script that would not work on current machines. Updates include:  port_end_c.mod_nowarning (this removed some blanks characters which were generating line to long warnings in nupdate)  bottom_friction_quadc_1.0e: added first version of ocean bottom friction.  bugfix_timer: corrected bug in timer code  buglet_cntl_io_fix.mod (corrected potential bug in mixed common block: fortran does not like characters and numbers mixed)  gsm9f406_nowarning (fixed some line-to-long warning messages from nupdate)  gwave_varlim_001_N048.mod: Ensures that gravity wave code does not encounter small variance buglet, see Snell et al 2022)  pstar_smooth08_N048: attempt to cure a strange problem with a two grid wave in atmosphere that emerges if model is run for millenia  smooth_stream_006.mod:  Adds additional smoothing to ocean stream function calculation to mostly cure 2 grid waves.       This created some significant changes to model. The pstar and ocean smoothing updates did as expected i.e. they removed two grid waves without further serious changes. The gwave update made no difference. This was because the pre-industrial variances were OK. The bottom friction only changed the deep ocean and the circumpolar current. The latter improved it compared to ocean reanalysis. Almost no change to surface temp/precip.  These changes are going to be documented in Valdes et al 2024.           2) tdaa - HadCM3B-M2.1aD - HadCM3B with MOSES2.1a and dynamic TRIFFID   The origin of this job is the PMIP2 project in around 2004. Michel Crucifix, then working at the Hadley Centre, created a HadCM3 version of the Cox et al (2000) HadCM3LC model. This version includes the bug fix related to the wrong surface energy balance that existed in the original Cox et al simulations. HOWEVER, at that time we had a significant problem. When we ran this job on our HPC computers, it gave different answers (0.75C different in the global mean). We could not locate the problem and for several years  had to have a MetOffice version and a Bristol version.   Eventually, Lois Steenman-Clarke at CGAM, Reading located the problem. It was a problem related to a data statement in a subroutine and an ambiguity of FORTRAN (does the data statement reset the constant every time the subroutine is called). Different FORTRAN compilers implemented this differently. At this point, we were then able to create a “true” standard version and benchmark it against a previous simulation. This became the starting point of the model.   There was also an issue with a pre-STASH modification (mosesii) we included in our version, which was actually meant for MOSES2.2, not 2.1, and removing this resulted in a good agreement between the Bristol and Met Office versions.  See these notes on our old wiki.                  Name       Date       Description       Impact                       2.b       2010-08       This is the initial setup. It was designed to be as similar as possible to 1.d with the only differences being related to MOSES1 to MOSES2.1. In practice, there is also a small difference related to run length and this version did not include the auto resubmit option of 1.d (which was already no longer functional)       This version was successfully benchmarked against the PMIP2 Hadley centre pre-industrial simulation. The benchmarking primarily focussed on temp/precip.                 2.c       2013-06       Same changes as in 1.e (also reset run length to be 100 years) but in addition, removed the gnum143.mod from the 2.b setup. This update sets the background ocean vertical tracer diffusivity to a background value. After extensive discussions with CGAM (especially Robin Smith) the consensus was that this update should be included in the low resolution model (HadCM3L) but not in HadCM3.       Benchmarked successfully. Saw little change from the ocean diffusivity change but this might be because of the short run lengths.                 2.d       2013-08       Same changes as in 1.f       Benchmarked successfully                 2.e       2014-08       Same changes as in 1.g Also modified pot_evap_chn_nooutput in order to reduce printed statements.       Not benchmarked                 2.f       2021-07       Same changes as in 1.h, but also included:  leaf_co2: corrected a bug in leaf_co2 calculation that did not impact science but did result in incorrect output values.  change_dark_respiration_ver02: Small improvement in TRIFFID by adopting changes from more recent models       Benchmarked successfully                 2.g       2022-10       Same changes as in 1.i       Similar changes as in 1.i           3) tdcf - HadCM3BL-M2.1aD - HadCM3BL with MOSES2.1a and dynamic TRIFFID   This job was developed from HadCM3B-M2.1aD and is scientifically identical except the resolution of the ocean. However, in addition, we have removed Iceland (as in FAMOUS). This allows us to run HadCM3L without flux correction.                  Name       Date       Description       Impact                       3.b       2011-06       This is identical to 2.b (i.e. equivalent HadCM3 simulation) except for resolution related issues (and a few things with processor count/run length)       This is a unique configuration so we did not have any benchmarks to compare with.                 3.c       2013-06       Identical changes to 2.c except that the gnum143.mod remains included       Statistically identical to 3.b                 3.d       2013-08       Identical changes to 2.d except that the gnum143.mod remains included       Statistically identical to 3.b                 3.e       2014-08       Identical changes to 2.e except that the gnum143.mod remains included       Not benchmarked                 3.f       2020-08       An interim version, somewhere between the 2.e and 2.f setup.       Not benchmarked                 3.g       2021-07       Identical changes to 2.f except that the gnum143.mod remains included       Not benchmarked                 3.h       2022-10       Identical changes to 2.g except that the gnum143.mod remains included       Similar changes to HadCM3           4) tfff - HadAM3B-N216-MOSES1   This is a relatively new configuration, first developed in 2021. It was developed from a standard HPCX setup job created by CGAM (xbafd). xbafd was developed from a version from the UK MetOffice. N216 was the standard forecasting-mode type job around 2000, and which was extensively used for storm case studies by CGAM/Uni Reading.   xbafd had a lot of old physics (e.g. single level soil scheme, different radiation etc.) which I did not want to reproduce. Indeed the philosophy was not to match the existing configuration of any high resolution version of the model but to focus on producing a high resolution version of HadAM3B which was as close as possible to the physics of the lower resolution model. Hence, the choices of physics parameterisations and corresponding modsets were driven by maintaining compatibility to HadAM3B. The only changes were for parameters that were known to be resolution dependent. This includes the RHCRIT parameters, diffusion, a known resolution dependence to the soil water infiltration code, land/sea precip parameters, gravity wave drag.   These were tuned to produce the best possible surface temperature and precipitation simulation. However, it was surprisingly difficult to get both right so a compromise had to be made.                  Name       Date       Description       Impact                       x.b       2021-07       Identical setup to HadAM3B (specifically xx) but with the following changes:  Changed diffusion and RHCRIT profiles. Changes land/sea parameters for large scale precip. Changed GW coefficients. Tweaks to diffusion/time filtering. Time step.  conv_eps_0.48  ls_eps_0.88: Both of the above are about the fraction of grid box it rains.  ddhlonly.txt: changes latitudinal divergence damping profile. Used in HadRM3 and seemed to be a good idea!  high_resolution: increased maximum resolution to 1152, though found this was too slow.       No benchmark to compare with.                 x.c       2022-10       Identical changes to 1i except parameters appropriate for N216.       Very small changes only.           ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_user_notes/Standard_swsvalde_UM_Model_jobs/",
        "teaser": null
      },{
        "title": "UMUI jobs in swsvalde",
        "excerpt":"  UMUI jobs in swsvalde  Introduction   When I started using the UM, I inherited a lot of different jobs from the Hadley Centre. These jobs covered the whole range of scientifically different versions of the model, from normal HadAM3-N48 (and HadAM3-N216), to HadSM3 and HadCM3-M1, and HadCM3-M2.1. However, the jobs often had lots of differences, due to different users, differences in STASH, the date when the job was created, different machines etc. etc. This made it very difficult to compare jobs and work out what was a true scientific difference, and what was just a path or machine technical difference. I also wanted to be able to submit to a range of different machines without having to make lots of changes to the job.   umui job structure aim   I therefore decided to create a set of jobs covering all of the major variants of the model, which:   a. When taking differences between model variants, the only differences were related to science. b. Standard modsets were all located together so path names were simple and clear. c. Standard naming of folders, using variable names for key locations, so that moving to different folder names on different machines requires just one simple change.   Moreover, I then implemented a script, clustersubmit (an extension of the UM provided umsubmit) which will automatically make the changes required for different machines, change the job from compile to run mode (all of our standard jobs are set to compile and stop), and also allows the user to select the queue, core numbers of NS and EW, and the run time.   Overall Structure   In the umui on puma, the user called swsvalde holds a series of experiments with different configurations of the model. Each experiment will have a number of jobs, with the highest letter representing the latest, most up-to-date version. When available, the original versions were successfully benchmarked against a “standard” from the Hadley centre. E.g., the HadCM3-M1 job tcsyb was run and output compared to a Hadley Centre equivalent. HOWEVER, subsequent versions may have made small changes to the science (and bug fixed errors) so that the latest versions may not be 100% scientifically identical to the original. If you are interested, you can go through the differences to help ascertain the changes. It is on my long to-do list, to document the changes but this will probably never happen!   Within each job, there is a standard structure. The path names etc use a standard naming convention based on some system variables, described below:   Key “system” variables   When a job is submitted, the scripts expect a number of shell variables to be defined. This is achieved through a script called setvars or setvars_4.5 or equivalent. On our BRIDGE machines, a user should include invoke this in their .profile file. Although we have also added a few extra definitions. In particular, we define a variable called DUMP2HOLD which is the folder which contains the job folder, with the input, output, and code folders (the name originates from an old national HPC machine which used this name). This folder needs to have sufficient space to handle the output from the job.   Within a umui job, go to Sub-Model Independent -&gt; Script Inserts and Modifications. There will be a further number of “Defined Environment Variables”. These are rarely (never) changed for a simulation.                  Name       Description       Typical Value                       ANCIL_ROOT       This is the root folder for most of the system wide ancil files (note that the precise location is defined below in the File and Directory naming section)       /home/swsvalde                 PV_ROOT       This is the root folder for most of the system wide modset files. (Note that the precise location is defined below in the File and Directory naming section)       /home/swsvalde                 UM_INPUT       Folder for various standard input files       $UMDIR/PUM_Input/vn4.5                 UM_OUTPUT       Folder for various output files. I don’t think this is used!       $HOME/PUM_Output/vn4.5                 TEMP       Temporary folder for a variety of files whilst model is running       $DUMP2HOLD/um/$RUNID/tmp                 IN       Temporary input file folder.       $TEMP           In the submission script (clustersubmit), the values for ANCIL_ROOT and PV_ROOT are changed to reflect the full pathname for the appropriate machine.   In addition, there are some further variables defined in: Sub-Model Independent -&gt; File &amp; Directory Naming. Time Convention &amp; Environment. Note that these variables point towards various folders, but the variables can be ignored subsequently. For instance, in the ancil section, you can completely ignore the variables defined below and give the folder location as something completely different. This is OK to do (provided you keep to the structures e.g., using $HOME or ~username) but it is perhaps a little bit less tidy/structured than using the variables below.                  Name       Description       Example Value                       MY_ANCIL       This should be the folder location for most of the ancil files for your job       $HOME/ancil/scotese/160_4_1deg  (See point 1 below). User can change to anything they want.                 ALT_ANCIL       This can be used if a few of your ancil files or coming from a different folder.       $ANCIL_ROOT/ancil/preind2  (But might not be used). User can change to anything they want.                 OZONE_ANCIL       This is used for the folder name for the ozone file. For the vast majority of our runs, we do not change ozone. Previously we needed to copy the ozone file but now we can simply give the ozone file as our pre-industrial standard       $ANCIL_ROOT/ancil/preind2   User can change to anything they want.                 MY_UPDATES       Location of your own modsets       $HOME/um_updates  (See point 1 below). User can change to anything they want.                 MY_DUMPS       Location of your dumps. This is not always used. It depends on the setting in the reconfiguration. It is useful when you are using the same dump file for many simulations.       $HOME/dumps  (See point 1 below) User can change to anything they want.                 MY_EXECS       Location of a standard executable. Again, this is only commonly used if using the same executable for lots of simulations.       $HOME/execs  (See point 1 below) User can change to anything they want.                 PV_UPDATES       This is the folder location for standard updates created (or maintained) by BRIDGE       $PV_ROOT/um_updates  (Rarely changed)                 PV_DUMPS       This is the folder location for standard dump files created (or maintained) by BRIDGE       $PV_ROOT/dumps   (Rarely changed)                 PV_EXECS       This is the folder location for standard executables created (or maintained) by BRIDGE. Rarely used for the main model but the reconfiguration executables are stored here as they rarely change.       $PV_ROOT/execs   (Rarely changed)                 UM_SPECTRAL       File for radiation spectral files. Rarely changes.       $UMDIR/vn$VN/ctldata  (Rarely changed)                 MODS       Modsets from the original UM distribution       $UM_INPUT/mods/source   (Rarely changed)                 MODS_SCRIPTS       Script modsets from the original UM distribution       $UM_INPUT/mods/scripts   (Rarely changed)                 MODS_SOURCE       Further modsets from the original UM distribution       $UM_INPUT/mods/source/clim   (Rarely changed)                 OVERRIDES       Folder for compiler overrides       $UM_INPUT/overrides   (Rarely changed)                 FAMOUS_MODS       Folder for FAMOUS modsets. This may also be used in HadCM3 setup       $UMDIR/../famous   (Rarely changed)                   If the variables are specified as $HOME, this will work for the user but will not work if another user copies your folder without them also copying the folder structure and contents. It is therefore better to give the path as ~username/ancil/scotese/160_4_1deg. This would work for any user without having to create a copy of the contents.            In addition to the variables above, we always use the following:       a. DATAM = $DUMP2HOLD/um/$RUNID/datam   b. DATAW= $DUMP2HOLD/um/$RUNID/dataw   c.  UCOMPDIR= $DUMP2HOLD/um/$RUNID/code   Modsets   All non-experimental modsets which are in addition (or have been changed from the standard release) are stored in a central location $PV_ROOT/um_updates. In many cases, over the years, I have received multiple copies of the same name modset. In about 2010, I compared all copies of the same file and found no substantive scientific differences.  A few same named modsets had differences in the comments but nothing else. However, many also included unnecessary blank characters at the end of each line, or the modset comments, which extended beyond row 72. This caused warning messages in the nupdate command which could obscure true problems. Similarly, some modsets added lines to the same location which again generated warning messages. Most were unimportant but there was an example (liked to adding water isotopes) where it could make a scientific change. Hence, I have processed all of the files in $PV_ROOT/um_updates so that they do not give any warnings in normal use. This means that they are probably not the same as any other version/copies that are around, but they should be scientifically identical (except for the isotope example above). If you do see a warning, you need to check it!   There are a few modsets that need to be different on different machines. The main one is a script modset to allow the submission of jobs to work. This will often be different on different machines because the submission method varies. he way we get around this is that if any modset in the umui has local in the name, then this means that it will be a machine dependent modset. In most cases, we normally make the actual file a symbolic link to the unique file on the machine itself. For instance, in the umui jobs, there is file called $PV_UPDATES/mpirun-local. If you logon to Bristol’s HPC machines then the file exists but is a symlink to mpirun-bc4 on bluecrystalp4, and mpirun-bp1 on bluepebble.   STASH   STASH output was standardised so that all versions of the model use the same STASH unless it is version specific (i.e., MOSES2.1/TRIFFID has additional outputs compared to MOSES1). The selected STASH is significantly smaller than in most Hadley Centre jobs and doesn’t use any climate meaning options. The reason I removed this is that I found it to be temperamental when there were disk space/quota problems which was common in early years and is occasionally still an issue currently.   The only exception to common STASH is with the high-resolution versions of HadAM3. The main point of using the high-resolution model is to look at extremes and hence we wish to have much larger volumes of output.   Further Changes   There are several options in the model where you can choose the fast version of the code, or one that is bit reproducible. They state that they are scientifically identical, and I assume this is the case. Jobs inherited from the Hadley Centre were very variable in the usage.     Until recently, we always selected the fast version, but I have recently discovered (2021) that the bit reproducible version is not slower (or in one case faster)! Hence, they are now all changed to bit reproducible except in one location because the isotope code was not coded for this option.   Summary   With these changes adopted, …   ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_user_notes/UMUI_jobs_in_swsvalde/",
        "teaser": null
      },{
        "title": "UM_tools_and_generic_tools",
        "excerpt":"  Documentation for useful tools  Introduction   When interacting with models and model results, some tools are useful for visualising (e.g., xconv, panoply), some tools are useful for files downloading (e.g., ftp_master), and some tools are useful for configuration data (ancillary files) manipulation (e.g., xancil, isla). We provide an overview of essential tools for common modeling work.   xconv   https://ncas-cms.github.io/xconv-doc Xconv is a program designed to convert model output into a format suitable for use in various plotting packages. Xconv is designed to be simple to use with a point and click, windows based interface. Xconv can read Met. Office Unified Model, Met. Office PP, GRIB, netCDF and grads format data. Data can be output in netCDF and grads format.   xancil   https://ncas-cms.github.io/xancil-doc/singlehtml/index.html Xancil is a X-windows based application for creating Unified Model ancillary files from netCDF input files.   panoply   ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadcm3_user_notes/UM_tools_and_generic_tools/",
        "teaser": null
      },{
        "title": "HadGEM workflow",
        "excerpt":"Archer2     run model   JASMIN (all raw data)     all raw data (150 TB)   paleo disk (owned by Charlie)   Archer2     Monthly means   BRIDGE silurian array disk: wb19586/hadgem3     ancils = ancils   comparison_data = CESM2   output_production = climate (last 100 years and restarts)   output_spinup = other experimnts, earlier parts of spinup   Version 10.7 outputs pp files Version 11.2 outputs netcdf  ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadgem_technical_notes/HadGEM_workflow/",
        "teaser": null
      },{
        "title": "Seb's HadGEM3 documentation on github",
        "excerpt":"Seb’s HadGEM3 documentation on github  ","categories": [],
        "tags": [],
        "url": "/UM_Bristol/hadgem_technical_notes/Seb's_HadGEM3_documentation_on_github/",
        "teaser": null
      },,{
    "title": "Editing Guide",
    "excerpt":"  Introduction   Our aim is to generate documentation that is useful, and remains useful in the future.  As such, it  needs to be in a format which (a) all users can easily contribute to, and (b) is future-proof.   We have decided to use a combination of ‘markdown’ (the file format) and ‘github’ (the version control system).  This combination is standard for large code documentation.   Markdown files are raw ascii text files, with some very basic formatting.  The idea is that it is easy to write, updates/changes are easily viewable, and should be relatively future-proof.  Here is a guide to some basic markdown syntax: https://www.markdownguide.org/basic-syntax/ .    Github is a version control system which is very popular for maintaining code and documentation.  You can read more about github here.   Reading the documentation   The documentation files are automatically pushed to a webpage, which is here: https://danlunt1976.github.io/UM_Bristol   You can also read the pages directly on github, here: https://github.com/danlunt1976/UM_Bristol . Start by clicking on the “README.md” file, which is the entry point: https://github.com/danlunt1976/UM_Bristol/blob/main/README.md   Writing the documentation   The documentation will be most useful if everyone can contribute to writing and maintaining it.   In order to contribute, you will need an account on github. Apply here for a (currently!) free account:  https://github.com/signup .  Once you have an account on github (see above), email Dan Lunt (d.j.lunt@bristol.ac.uk) with your github username, and he will invite you to be a collaborator.  You will then have edit-rights.   Easiest entry-point for writing documentation   (1) Once logged into your github account, go to the web interface for the documentation repository: https://github.com/danlunt1976/UM_Bristol   (2) Click on one of the .md files   (3) Click on the pencil icon above the file text (‘Edit this file’).   (4) Make some edits.   (5) Click on the green button “Commit changes…”   (6) Write a “Commit message” in the upper box, and leaving “Commit directly to the main branch” selected.   (7) Click on “Commit changes”   (8) Have a beer.   More advanced writing (from a Windows machine)   Instead of editing the wiki directly as above, you can download a ‘clone’ of the repository to your local machine, and edit it there, and then ‘push’ back to the main repository.  Before ‘pushing’ you should ‘pull’ form the main repository, to ensure that you do not overwrite or clash with anyone else’s changes.  You can do this pushing and pulling using the ‘Github Desktop’ app.  The main benefit of editing locally is that you can take advantage of some nice tools for writing and viewing markdown files and sites.  One such editing tool is ‘Obsidian’.  Here are some instructions:   (1) Download the ‘GitHub Desktop’ app for Windows: https://desktop.github.com/download/   (2) Clone a copy of the repository, following these instructions: https://docs.github.com/en/desktop/adding-and-cloning-repositories/cloning-a-repository-from-github-to-github-desktop .  You can choose anywhere on your local filesystem to hold your local copy.   (3) You can edit the .md files in your local copy using whatever editing sofware you wish (e.g. Wordpad).  However, to have access to some useful tools, you can use a specific markdown file editor.  One example is Obsidian.  Download it to your desktop here:  https://obsidian.md/download .   Open Obsidian and click on ‘Open folder as vault’.  It should then be fairly intuitive how to edit files.   (4) Once you have finished editing, re-open GitHub Desktop.  Click on ‘Fetch origin’ to ‘pull’ any changes that anyone else has made.  Then write a comment in the ‘Summary’ box, and then click on ‘Commit to main’   (5) Click on ‘Push origin’   (6) Have another beer.   From a MAC   I’m sure it’s possible, but I have no idea how.   From a Linux machine.   Also definitely possible.  I have local repositories on eocene that Greg set up, for my code repositories.  I (Dan) have some notes on this if anyone is interested (and then you can update these instructions!).   ","url": "http://localhost:4000/UM_Bristol/Editing_guide/"
  },{
    "title": "HadCM3 technical notes",
    "excerpt":"This contains links to technical notes about HadCM3.   This is currently mostly notes based on meetings with Paul, and is not really of use/interest to most users of the model.   Users should instead go to HadCM3_user_notes.   PUMA   Model_install   Standard_jobs   Clustersubmit   Ensembles   Downloading   Backups   Local_hardware   University_HPC   Documentation   ","url": "http://localhost:4000/UM_Bristol/hadcm3_technical_notes/"
  },{
    "title": "HadCM3 user notes",
    "excerpt":"Getting_started_with_HadCM3   UMUI jobs in swsvalde   Standard swsvalde UM Model jobs   HadCM3_Workflow   Documentation for clustersubmit   Documentation for ensembles   HadCM3 for CMIP7   Documentation for tools   Collaborations   ","url": "http://localhost:4000/UM_Bristol/hadcm3_user_notes/"
  },{
    "title": "HadGEM technical notes",
    "excerpt":"HadGEM_workflow   Seb’s HadGEM3 documentation on github   ","url": "http://localhost:4000/UM_Bristol/hadgem_technical_notes/"
  },{
    "title": "Pages by Collection",
    "excerpt":"         Collections                                                                                                             hadcm3_user_notes                                                         Accessing Scotese                                        CMIP7 ancillaries                                        CMIP7 model                                        CMIP7 simulations                                        Collaborations                                        Collaborations with Scotese simulations                                        Documentation for clustersubmit                                        Getting started with HadCM3                                        HadCM3 for CMIP7                                        HadCM3 Workflow                                        Nils notes for running HadCM3B                                        Running Ensembles on bluecrystalp4                                        Standard swsvalde UM Model jobs                                        UMUI jobs in swsvalde                                        UM_tools_and_generic_tools                                                                                                                                                                                                    hadcm3_technical_notes                                                         Backups                                        Clustersubmit                                        Documentation                                        Downloading                                        Ensembles                                        Local hardware                                        Model_install                                        PUMA                                        Standard jobs                                        University HPC                                                                                                                                                                                                                                                                hadgem_technical_notes                                                         HadGEM workflow                                        Seb's HadGEM3 documentation on github                                                                                                                                                                        hadcm3_user_notes                                                      Accessing Scotese                                                                     February 17, 2025                                                                           9 minute read                                Accessing Phanerozoic simulation data                                                            CMIP7 ancillaries                                                                     February 17, 2025                                                                           less than 1 minute read                                CMIP7 ancillaries                                                            CMIP7 model                                                                     February 17, 2025                                                                           less than 1 minute read                                CMIP7 model                                                            CMIP7 simulations                                                                     February 17, 2025                                                                           less than 1 minute read                                CMIP7 simulations                                                            Collaborations                                                                     February 17, 2025                                                                           less than 1 minute read                                Collaborations                                                            Collaborations with Scotese simulations                                                                     February 17, 2025                                                                           2 minute read                                Collaborations with Scotese simulations                                                            Documentation for clustersubmit                                                                     February 17, 2025                                                                           7 minute read                                Documentation for clustersubmit                                                            Getting started with HadCM3                                                                     February 17, 2025                                                                           16 minute read                                Getting started with HadCM3                                                            HadCM3 for CMIP7                                                                     February 17, 2025                                                                           less than 1 minute read                                HadCM3 for CMIP7                                                            HadCM3 Workflow                                                                     February 17, 2025                                                                           5 minute read                                HadCM3 Workflow                                                            Nils notes for running HadCM3B                                                                     February 17, 2025                                                                           8 minute read                                Notes for running HadCM3B                                                            Running Ensembles on bluecrystalp4                                                                     February 17, 2025                                                                           11 minute read                                Running Ensembles on bluecrystalp4                                                            Standard swsvalde UM Model jobs                                                                     February 17, 2025                                                                           9 minute read                                Standard swsvalde UM Model jobs                                                            UMUI jobs in swsvalde                                                                     February 17, 2025                                                                           8 minute read                                UMUI jobs in swsvalde                                                            UM_tools_and_generic_tools                                                                     February 17, 2025                                                                           less than 1 minute read                                UM_tools_and_generic_tools                                                                                 hadcm3_technical_notes                                                      Backups                                                                     February 17, 2025                                                                           less than 1 minute read                                Backups                                                            Clustersubmit                                                                     February 17, 2025                                                                           less than 1 minute read                                Clustersubmit                                                            Documentation                                                                     February 17, 2025                                                                           less than 1 minute read                                Documentation                                                            Downloading                                                                     February 17, 2025                                                                           less than 1 minute read                                Downloading                                                            Ensembles                                                                     February 17, 2025                                                                           less than 1 minute read                                Ensembles                                                            Local hardware                                                                     February 17, 2025                                                                           less than 1 minute read                                Local hardware                                                            Model_install                                                                     February 17, 2025                                                                           less than 1 minute read                                Model_install                                                            PUMA                                                                     February 17, 2025                                                                           less than 1 minute read                                PUMA                                                            Standard jobs                                                                     February 17, 2025                                                                           less than 1 minute read                                Standard jobs                                                            University HPC                                                                     February 17, 2025                                                                           12 minute read                                University HPC                                                                                                         hadgem_technical_notes                                                      HadGEM workflow                                                                     February 17, 2025                                                                           less than 1 minute read                                HadGEM workflow                                                            Seb’s HadGEM3 documentation on github                                                                     February 17, 2025                                                                           less than 1 minute read                                Seb’s HadGEM3 documentation on github                                        ","url": "http://localhost:4000/UM_Bristol/"
  }]
